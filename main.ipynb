{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import importlib\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SGECluster\n",
    "import socket\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, MaxPool2D, Conv2D, Flatten, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37727</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>540.71 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37727' processes=1 threads=4, memory=540.71 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hostname = socket.gethostname()\n",
    "n_workers = 1\n",
    "n_cores = 4\n",
    "\n",
    "wks2 = \"wn-wks2.fe.hhi.de\"\n",
    "gpu1 = \"wn-gpu1.fe.hhi.de\"\n",
    "gpu2 = \"wn-gpu-104-01.fe.hhi.de\"\n",
    "\n",
    "if hostname == wks2:\n",
    "    path = \"/data/cluster/projects/infineon-radar/daq_x-har/3_Walking_converted/recording-2020-01-28_11-31-55\"\n",
    "    mem = \"20G\"      # Allocated memory is critical. For this example it must be at least 16GB \n",
    "    q = \"wn-37.q\"    # Check current queue status on https://hpc-management.fe.hhi.de/wn/phpqstat/\n",
    "    \n",
    "    cluster = SGECluster(n_workers=n_workers, cores=n_cores, memory=mem,\n",
    "                        resource_spec=f\"h_vmem={mem}\", host=hostname, queue=q,\n",
    "                         job_extra=[\"-v MKL_NUM_THREADS=1,NUMEXPR_NUM_THREADS=1,OMP_NUM_THREADS=1\"])\n",
    "elif hostname in (gpu1, gpu2):\n",
    "    path = os.getcwd() + \"/data\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"  # Check current status with nvidia-smi and pick GPU from 0-3\n",
    "    cluster = LocalCluster(n_workers=n_workers, threads_per_worker=n_cores, host=hostname)\n",
    "else:\n",
    "    raise ValueError(f\"{hostname} is not a supported host. Please run this example on {wks}, {gpu1} or {gpu2}.\")\n",
    "    \n",
    "\n",
    "    \n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers=n_workers)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset: tf.data.Dataset, validation_data_fraction: float):\n",
    "\n",
    "    validation_data_percent = round(validation_data_fraction * 100)\n",
    "    if not (0 <= validation_data_percent <= 100):\n",
    "        raise ValueError(\"validation data fraction must be âˆˆ [0,1]\")\n",
    "\n",
    "    dataset = dataset.enumerate()\n",
    "    train_dataset = dataset.filter(lambda f, data: f % 100 >= validation_data_percent)\n",
    "    validation_dataset = dataset.filter(lambda f, data: f % 100 < validation_data_percent)\n",
    "\n",
    "    # remove enumeration\n",
    "    train_dataset = train_dataset.map(lambda f, data: data)\n",
    "    validation_dataset = validation_dataset.map(lambda f, data: data)\n",
    "\n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "def data_prep(path):\n",
    "    dataset_raw = np.load(path, allow_pickle=True)\n",
    "    arrays = np.array(dataset_raw[()][\"data\"])\n",
    "    arrays = arrays - arrays.min()\n",
    "    arrays = arrays/arrays.max()\n",
    "    arrays -= arrays.mean()\n",
    "    arrays = arrays/arrays.std()\n",
    "    if np.isnan(arrays).any() or np.isinf(arrays).any():\n",
    "        raise \"data have imperfections\"\n",
    "    print(arrays.shape)\n",
    "    labels = dataset_raw[()][\"label\"]\n",
    "    labels = np.array([x-np.array(list(set(labels))).min() for x in labels])\n",
    "    print(labels.shape)\n",
    "    return (arrays, labels)\n",
    "\n",
    "def load_data(path):\n",
    "    data, label = data_prep(path)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "    dataset = dataset.shuffle(100000)\n",
    "    train_dataset, rest = split_dataset(dataset, 0.3)\n",
    "    test_dataset, valid_dataset = split_dataset(rest, 0.5)\n",
    "    train_data = train_dataset.shuffle(1000).batch(10)\n",
    "    valid_data = valid_dataset.batch(10)\n",
    "    test_data = test_dataset.batch(10)\n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "\n",
    "def make_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    Input((1,30,30)),\n",
    "    Conv2D(filters = 8, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"c1\", data_format=\"channels_first\"),\n",
    "    Conv2D(filters = 16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"c2\", data_format=\"channels_first\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(1,1),padding=\"same\", name=\"m1\", data_format=\"channels_first\"),\n",
    "    \n",
    "    Conv2D(filters = 16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"c3\", data_format=\"channels_first\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(1,1),padding=\"same\", name=\"m2\",data_format=\"channels_first\"),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation=\"relu\", use_bias=True),\n",
    "    Dense(5, activation=\"softmax\", use_bias=True)])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59003, 1, 30, 30)\n",
      "(59003,)\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = load_data(\"/home/fe/khodabakhshandeh/Projects/radar/radar-ml/Python/data/Config G/box_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "model.fit(train_data, verbose=1, validation_data=valid_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    885/Unknown - 2s 2ms/step - loss: 0.0989 - accuracy: 0.9655"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09893597595326135, 0.9655367]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save(\"base_model_2\")\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"base_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_data(train_data):\n",
    "    train_data.shuffle(1000)\n",
    "    _, data = split_dataset(train_data, 0.1)\n",
    "    return data\n",
    "\n",
    "def UCB1(mu, n, t):\n",
    "    P = np.sqrt(2*np.log10(t)/n)\n",
    "    P = P\n",
    "    print(\"p:\", P)\n",
    "    index = np.argmax(np.add(mu, P))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1287 - accuracy: 0.9474/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1466 - accuracy: 0.9433/n\n",
      "reward: 0.0\n",
      "n: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "##############\n",
      "index: 1\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1352 - accuracy: 0.9469/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1464 - accuracy: 0.9440/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "##############\n",
      "index: 2\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1361 - accuracy: 0.9455/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1339 - accuracy: 0.9483/n\n",
      "reward: 0.7246987159361141\n",
      "n: [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 3\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9486/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1474 - accuracy: 0.9424/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 4\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1303 - accuracy: 0.9519/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1457 - accuracy: 0.9440/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 5\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1400 - accuracy: 0.9455/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1422 - accuracy: 0.9426/n\n",
      "reward: 0.2806247745739644\n",
      "n: [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 6\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1432 - accuracy: 0.9438/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1368 - accuracy: 0.9452/n\n",
      "reward: 1.1337740293903522\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 7\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1486 - accuracy: 0.9388/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1458 - accuracy: 0.9431/n\n",
      "reward: 0.7887847616789037\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 8\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1454 - accuracy: 0.9414/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1406 - accuracy: 0.9471/n\n",
      "reward: 0.9822456064340231\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 9\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1389 - accuracy: 0.9443/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1501 - accuracy: 0.9395/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 10\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1505 - accuracy: 0.9440/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1376 - accuracy: 0.9460/n\n",
      "reward: 1.7916350881451266\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 11\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1419 - accuracy: 0.9431/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1457 - accuracy: 0.9429/n\n",
      "reward: 0.11580196328993499\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.11580196\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 12\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1431 - accuracy: 0.9419/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1523 - accuracy: 0.9386/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.11580196\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 13\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1508 - accuracy: 0.9388/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1529 - accuracy: 0.9388/n\n",
      "reward: 0.2943070494615586\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.11580196\n",
      " 0.         0.29430705 0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 14\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1482 - accuracy: 0.9402/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1463 - accuracy: 0.9405/n\n",
      "reward: 0.6994824642090276\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 15\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1415 - accuracy: 0.9467/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1613 - accuracy: 0.9324/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 16\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1507 - accuracy: 0.9426/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1519 - accuracy: 0.9376/n\n",
      "reward: 0.3740527245120441\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 17\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1550 - accuracy: 0.9379/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1490 - accuracy: 0.9398/n\n",
      "reward: 1.1012596667555743\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 1.10125967\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 18\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1520 - accuracy: 0.9414/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1440 - accuracy: 0.9417/n\n",
      "reward: 1.3062320249432349\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 1.10125967\n",
      " 1.30623202 0.        ]\n",
      "##############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 19\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9383- 1s 4 - 1s 3ms/step - loss: 0.1591 - accuracy: 0.93 - 1s 3ms/step - - 1s 3ms/step - los - 1s 3ms/step - loss: 0.1589 - accuracy/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9390/n\n",
      "reward: 0.6695053785806533\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         1.79163509 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 1.10125967\n",
      " 1.30623202 0.66950538]\n",
      "##############\n",
      "p: [1.62617299 1.62617299 1.62617299 1.62617299 1.62617299 1.62617299\n",
      " 1.62617299 1.62617299 1.62617299 1.62617299 1.62617299 1.62617299\n",
      " 1.62617299 1.62617299 1.62617299 1.62617299 1.62617299 1.62617299\n",
      " 1.62617299 1.62617299]\n",
      "RL\n",
      "index: 10\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9431/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1579 - accuracy: 0.9376/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 1.10125967\n",
      " 1.30623202 0.66950538]\n",
      "##############\n",
      "p: [1.63854977 1.63854977 1.63854977 1.63854977 1.63854977 1.63854977\n",
      " 1.63854977 1.63854977 1.63854977 1.63854977 1.15862966 1.63854977\n",
      " 1.63854977 1.63854977 1.63854977 1.63854977 1.63854977 1.63854977\n",
      " 1.63854977 1.63854977]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1570 - accuracy: 0.9367/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1484 - accuracy: 0.9402/n\n",
      "reward: 1.3611220175650165\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 1.13377403 0.78878476 0.98224561 0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 1.10125967\n",
      " 1.33367702 0.66950538]\n",
      "##############\n",
      "p: [1.65028957 1.65028957 1.65028957 1.65028957 1.65028957 1.65028957\n",
      " 1.65028957 1.65028957 1.65028957 1.65028957 1.16693095 1.65028957\n",
      " 1.65028957 1.65028957 1.65028957 1.65028957 1.65028957 1.65028957\n",
      " 1.16693095 1.65028957]\n",
      "RL\n",
      "index: 6\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1500 - accuracy: 0.9407/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1562 - accuracy: 0.9388- 1s 3ms/step - loss: 0.1550 - accuracy: 0/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 2. 1.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 0.56688701 0.78878476 0.98224561 0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 1.10125967\n",
      " 1.33367702 0.66950538]\n",
      "##############\n",
      "p: [1.66145192 1.66145192 1.66145192 1.66145192 1.66145192 1.66145192\n",
      " 1.17482392 1.66145192 1.66145192 1.66145192 1.17482392 1.66145192\n",
      " 1.66145192 1.66145192 1.66145192 1.66145192 1.66145192 1.66145192\n",
      " 1.17482392 1.66145192]\n",
      "RL\n",
      "index: 17\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9362/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1532 - accuracy: 0.9376/n\n",
      "reward: 0.5624659427142321\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 1.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 0.56688701 0.78878476 0.98224561 0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 0.8318628\n",
      " 1.33367702 0.66950538]\n",
      "##############\n",
      "p: [1.67208852 1.67208852 1.67208852 1.67208852 1.67208852 1.67208852\n",
      " 1.18234513 1.67208852 1.67208852 1.67208852 1.18234513 1.67208852\n",
      " 1.67208852 1.67208852 1.67208852 1.67208852 1.67208852 1.18234513\n",
      " 1.18234513 1.67208852]\n",
      "RL\n",
      "index: 8\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9410/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1549 - accuracy: 0.9350/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 2. 2. 1.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 0.56688701 0.78878476 0.4911228  0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 0.8318628\n",
      " 1.33367702 0.66950538]\n",
      "##############\n",
      "p: [1.68224454 1.68224454 1.68224454 1.68224454 1.68224454 1.68224454\n",
      " 1.18952652 1.68224454 1.18952652 1.68224454 1.18952652 1.68224454\n",
      " 1.68224454 1.68224454 1.68224454 1.68224454 1.68224454 1.18952652\n",
      " 1.18952652 1.68224454]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1523 - accuracy: 0.9379/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1628 - accuracy: 0.9333- 1s 3ms/step - lo/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 1. 2. 1. 2. 1. 1. 1. 1. 1. 1. 2. 3. 1.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 0.56688701 0.78878476 0.4911228  0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 0.8318628\n",
      " 0.88911801 0.66950538]\n",
      "##############\n",
      "p: [1.69195967 1.69195967 1.69195967 1.69195967 1.69195967 1.69195967\n",
      " 1.19639616 1.69195967 1.19639616 1.69195967 1.19639616 1.69195967\n",
      " 1.69195967 1.69195967 1.69195967 1.69195967 1.69195967 1.19639616\n",
      " 0.97685337 1.69195967]\n",
      "RL\n",
      "index: 7\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1495 - accuracy: 0.9440- 1s 3ms/step - loss: 0.1490 - accuracy: /n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1498 - accuracy: 0.9367/n\n",
      "reward: 0.4692236555052849\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 1. 2. 3. 1.]\n",
      "mu: [0.         0.         0.72469872 0.         0.         0.28062477\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 0.8318628\n",
      " 0.88911801 0.66950538]\n",
      "##############\n",
      "p: [1.70126896 1.70126896 1.70126896 1.70126896 1.70126896 1.70126896\n",
      " 1.20297882 1.20297882 1.20297882 1.70126896 1.20297882 1.70126896\n",
      " 1.70126896 1.70126896 1.70126896 1.70126896 1.70126896 1.20297882\n",
      " 0.98222809 1.70126896]\n",
      "RL\n",
      "index: 2\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1429 - accuracy: 0.9419/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1527 - accuracy: 0.9405/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 2. 1. 1. 1. 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 1. 2. 3. 1.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.28062477\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.69948246 0.         0.37405272 0.8318628\n",
      " 0.88911801 0.66950538]\n",
      "##############\n",
      "p: [1.7102035  1.7102035  1.20929649 1.7102035  1.7102035  1.7102035\n",
      " 1.20929649 1.20929649 1.20929649 1.7102035  1.20929649 1.7102035\n",
      " 1.7102035  1.7102035  1.7102035  1.7102035  1.7102035  1.20929649\n",
      " 0.98738645 1.7102035 ]\n",
      "RL\n",
      "index: 14\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1545 - accuracy: 0.9390/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1517 - accuracy: 0.9390/n\n",
      "reward: 0.7780546091803227\n",
      "n: [1. 1. 2. 1. 1. 1. 2. 2. 2. 1. 2. 1. 1. 1. 2. 1. 1. 2. 3. 1.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.28062477\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.73876854 0.         0.37405272 0.8318628\n",
      " 0.88911801 0.66950538]\n",
      "##############\n",
      "p: [1.718791   1.718791   1.21536877 1.718791   1.718791   1.718791\n",
      " 1.21536877 1.21536877 1.21536877 1.718791   1.21536877 1.718791\n",
      " 1.718791   1.718791   1.21536877 1.718791   1.718791   1.21536877\n",
      " 0.99234445 1.718791  ]\n",
      "RL\n",
      "index: 19\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1380 - accuracy: 0.9448/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1514 - accuracy: 0.9374/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 2. 1. 1. 1. 2. 2. 2. 1. 2. 1. 1. 1. 2. 1. 1. 2. 3. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.28062477\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.89581754 0.11580196\n",
      " 0.         0.29430705 0.73876854 0.         0.37405272 0.8318628\n",
      " 0.88911801 0.33475269]\n",
      "##############\n",
      "p: [1.72705628 1.72705628 1.22121321 1.72705628 1.72705628 1.72705628\n",
      " 1.22121321 1.22121321 1.22121321 1.72705628 1.22121321 1.72705628\n",
      " 1.72705628 1.72705628 1.22121321 1.72705628 1.72705628 1.22121321\n",
      " 0.99711641 1.22121321]\n",
      "RL\n",
      "index: 10\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1492 - accuracy: 0.9412/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1493 - accuracy: 0.9357/n\n",
      "reward: 0.4989660553927989\n",
      "n: [1. 1. 2. 1. 1. 1. 2. 2. 2. 1. 3. 1. 1. 1. 2. 1. 1. 2. 3. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.28062477\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.11580196\n",
      " 0.         0.29430705 0.73876854 0.         0.37405272 0.8318628\n",
      " 0.88911801 0.33475269]\n",
      "##############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [1.7350216  1.7350216  1.22684554 1.7350216  1.7350216  1.7350216\n",
      " 1.22684554 1.22684554 1.22684554 1.7350216  1.00171519 1.7350216\n",
      " 1.7350216  1.7350216  1.22684554 1.7350216  1.7350216  1.22684554\n",
      " 1.00171519 1.22684554]\n",
      "RL\n",
      "index: 16\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1442 - accuracy: 0.9431/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1510 - accuracy: 0.9381/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 2. 1. 1. 1. 2. 2. 2. 1. 3. 1. 1. 1. 2. 1. 2. 2. 3. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.28062477\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.11580196\n",
      " 0.         0.29430705 0.73876854 0.         0.18702636 0.8318628\n",
      " 0.88911801 0.33475269]\n",
      "##############\n",
      "p: [1.74270706 1.74270706 1.23227998 1.74270706 1.74270706 1.74270706\n",
      " 1.23227998 1.23227998 1.23227998 1.74270706 1.00615239 1.74270706\n",
      " 1.74270706 1.74270706 1.23227998 1.74270706 1.23227998 1.23227998\n",
      " 1.00615239 1.23227998]\n",
      "RL\n",
      "index: 17\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1532 - accuracy: 0.9410/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1493 - accuracy: 0.9424/n\n",
      "reward: 0.8928989530929046\n",
      "n: [1. 1. 2. 1. 1. 1. 2. 2. 2. 1. 3. 1. 1. 1. 2. 1. 2. 3. 3. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.28062477\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.11580196\n",
      " 0.         0.29430705 0.73876854 0.         0.18702636 0.85220819\n",
      " 0.88911801 0.33475269]\n",
      "##############\n",
      "p: [1.7501308  1.7501308  1.23752936 1.7501308  1.7501308  1.7501308\n",
      " 1.23752936 1.23752936 1.23752936 1.7501308  1.01043849 1.7501308\n",
      " 1.7501308  1.7501308  1.23752936 1.7501308  1.23752936 1.01043849\n",
      " 1.01043849 1.23752936]\n",
      "RL\n",
      "index: 13\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1484 - accuracy: 0.9414/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9433/n\n",
      "reward: 1.0457981253996325\n",
      "n: [1. 1. 2. 1. 1. 1. 2. 2. 2. 1. 3. 1. 1. 2. 2. 1. 2. 3. 3. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.28062477\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.11580196\n",
      " 0.         0.67005259 0.73876854 0.         0.18702636 0.85220819\n",
      " 0.88911801 0.33475269]\n",
      "##############\n",
      "p: [1.75730933 1.75730933 1.24260535 1.75730933 1.75730933 1.75730933\n",
      " 1.24260535 1.24260535 1.24260535 1.75730933 1.01458302 1.75730933\n",
      " 1.75730933 1.24260535 1.24260535 1.75730933 1.24260535 1.01458302\n",
      " 1.01458302 1.24260535]\n",
      "RL\n",
      "index: 5\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1574 - accuracy: 0.9333/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9381/n\n",
      "reward: 0.7700655511580385\n",
      "n: [1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 3. 1. 1. 2. 2. 1. 2. 3. 3. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.11580196\n",
      " 0.         0.67005259 0.73876854 0.         0.18702636 0.85220819\n",
      " 0.88911801 0.33475269]\n",
      "##############\n",
      "p: [1.76425763 1.76425763 1.24751854 1.76425763 1.76425763 1.24751854\n",
      " 1.24751854 1.24751854 1.24751854 1.76425763 1.01859462 1.76425763\n",
      " 1.76425763 1.24751854 1.24751854 1.76425763 1.24751854 1.01859462\n",
      " 1.01859462 1.24751854]\n",
      "RL\n",
      "index: 14\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1496 - accuracy: 0.9414/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1457 - accuracy: 0.9417/n\n",
      "reward: 0.8889245425047456\n",
      "n: [1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 3. 1. 1. 2. 3. 1. 2. 3. 3. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.11580196\n",
      " 0.         0.67005259 0.78882054 0.         0.18702636 0.85220819\n",
      " 0.88911801 0.33475269]\n",
      "##############\n",
      "p: [1.7709894  1.7709894  1.25227861 1.7709894  1.7709894  1.25227861\n",
      " 1.25227861 1.25227861 1.25227861 1.7709894  1.02248121 1.7709894\n",
      " 1.7709894  1.25227861 1.02248121 1.7709894  1.25227861 1.02248121\n",
      " 1.02248121 1.25227861]\n",
      "RL\n",
      "index: 13\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1498 - accuracy: 0.9376/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1476 - accuracy: 0.9431/n\n",
      "reward: 0.7271458305178747\n",
      "n: [1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 3. 1. 1. 3. 3. 1. 2. 3. 3. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.11580196\n",
      " 0.         0.68908367 0.78882054 0.         0.18702636 0.85220819\n",
      " 0.88911801 0.33475269]\n",
      "##############\n",
      "p: [1.77751714 1.77751714 1.25689443 1.77751714 1.77751714 1.25689443\n",
      " 1.25689443 1.25689443 1.25689443 1.77751714 1.02625    1.77751714\n",
      " 1.77751714 1.02625    1.02625    1.77751714 1.25689443 1.02625\n",
      " 1.02625    1.25689443]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1510 - accuracy: 0.9400/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1401 - accuracy: 0.9498/n\n",
      "reward: 1.5935707795059508\n",
      "n: [1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 3. 1. 1. 3. 3. 1. 2. 3. 4. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.11580196\n",
      " 0.         0.68908367 0.78882054 0.         0.18702636 0.85220819\n",
      " 1.06523121 0.33475269]\n",
      "##############\n",
      "p: [1.78385235 1.78385235 1.26137409 1.78385235 1.78385235 1.26137409\n",
      " 1.26137409 1.26137409 1.26137409 1.78385235 1.02990764 1.78385235\n",
      " 1.78385235 1.02990764 1.02990764 1.78385235 1.26137409 1.02990764\n",
      " 0.89192618 1.26137409]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1541 - accuracy: 0.9381/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1482 - accuracy: 0.9386/n\n",
      "reward: 1.0957750074005508\n",
      "n: [1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 3. 1. 1. 3. 3. 1. 2. 3. 5. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.11580196\n",
      " 0.         0.68908367 0.78882054 0.         0.18702636 0.85220819\n",
      " 1.07133997 0.33475269]\n",
      "##############\n",
      "p: [1.79000558 1.79000558 1.26572509 1.79000558 1.79000558 1.26572509\n",
      " 1.26572509 1.26572509 1.26572509 1.79000558 1.0334602  1.79000558\n",
      " 1.79000558 1.0334602  1.0334602  1.79000558 1.26572509 1.0334602\n",
      " 0.80051483 1.26572509]\n",
      "RL\n",
      "index: 11\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1528 - accuracy: 0.9398/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9362/n\n",
      "reward: 0.5093290304565452\n",
      "n: [1. 1. 2. 1. 1. 2. 2. 2. 2. 1. 3. 2. 1. 3. 3. 1. 2. 3. 5. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.56688701 0.62900421 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.78882054 0.         0.18702636 0.85220819\n",
      " 1.07133997 0.33475269]\n",
      "##############\n",
      "p: [1.79598656 1.79598656 1.26995427 1.79598656 1.79598656 1.26995427\n",
      " 1.26995427 1.26995427 1.26995427 1.79598656 1.03691332 1.26995427\n",
      " 1.79598656 1.03691332 1.03691332 1.79598656 1.26995427 1.03691332\n",
      " 0.80318961 1.26995427]\n",
      "RL\n",
      "index: 7\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9407/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1511 - accuracy: 0.9393/n\n",
      "reward: 0.7677261327196534\n",
      "n: [1. 1. 2. 1. 1. 2. 2. 3. 2. 1. 3. 2. 1. 3. 3. 1. 2. 3. 5. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.56688701 0.67524485 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.78882054 0.         0.18702636 0.85220819\n",
      " 1.07133997 0.33475269]\n",
      "##############\n",
      "p: [1.80180426 1.80180426 1.27406801 1.80180426 1.80180426 1.27406801\n",
      " 1.27406801 1.04027217 1.27406801 1.80180426 1.04027217 1.27406801\n",
      " 1.80180426 1.04027217 1.04027217 1.80180426 1.27406801 1.04027217\n",
      " 0.80579136 1.27406801]\n",
      "RL\n",
      "index: 17\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1517 - accuracy: 0.9402/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1466 - accuracy: 0.9407/n\n",
      "reward: 1.0104733042840288\n",
      "n: [1. 1. 2. 1. 1. 2. 2. 3. 2. 1. 3. 2. 1. 3. 3. 1. 2. 4. 5. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.56688701 0.67524485 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.78882054 0.         0.18702636 0.89177447\n",
      " 1.07133997 0.33475269]\n",
      "##############\n",
      "p: [1.80746699 1.80746699 1.27807216 1.80746699 1.80746699 1.27807216\n",
      " 1.27807216 1.04354155 1.27807216 1.80746699 1.04354155 1.27807216\n",
      " 1.80746699 1.04354155 1.04354155 1.80746699 1.27807216 0.90373349\n",
      " 0.80832381 1.27807216]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1510 - accuracy: 0.9371/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1464 - accuracy: 0.9383/n\n",
      "reward: 0.9593556499353975\n",
      "n: [1. 1. 2. 1. 1. 2. 2. 3. 2. 1. 3. 2. 1. 3. 3. 1. 2. 4. 6. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.56688701 0.67524485 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.78882054 0.         0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [1.81298245 1.81298245 1.28197218 1.81298245 1.81298245 1.28197218\n",
      " 1.28197218 1.0467259  1.28197218 1.81298245 1.0467259  1.28197218\n",
      " 1.81298245 1.0467259  1.0467259  1.81298245 1.28197218 0.90649122\n",
      " 0.74014698 1.28197218]\n",
      "RL\n",
      "index: 6\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1499 - accuracy: 0.9400- 1s 3ms/step - loss: 0./n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1542 - accuracy: 0.9395/n\n",
      "reward: 0.07367913315205711\n",
      "n: [1. 1. 2. 1. 1. 2. 3. 3. 2. 1. 3. 2. 1. 3. 3. 1. 2. 4. 6. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.40248439 0.67524485 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.78882054 0.         0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.81835778 1.81835778 1.28577312 1.81835778 1.81835778 1.28577312\n",
      " 1.04982936 1.04982936 1.28577312 1.81835778 1.04982936 1.28577312\n",
      " 1.81835778 1.04982936 1.04982936 1.81835778 1.28577312 0.90917889\n",
      " 0.74234146 1.28577312]\n",
      "RL\n",
      "index: 14\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1507 - accuracy: 0.9371/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1543 - accuracy: 0.9338- 1s 4ms/step - loss: 0.1533 - /n\n",
      "reward: 0.13252729410582986\n",
      "n: [1. 1. 2. 1. 1. 2. 3. 3. 2. 1. 3. 2. 1. 3. 4. 1. 2. 4. 6. 2.]\n",
      "mu: [0.         0.         0.36234936 0.         0.         0.52534516\n",
      " 0.40248439 0.67524485 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.62474723 0.         0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.82359964 1.82359964 1.28947967 1.82359964 1.82359964 1.28947967\n",
      " 1.05285575 1.05285575 1.28947967 1.82359964 1.05285575 1.28947967\n",
      " 1.82359964 1.05285575 0.91179982 1.82359964 1.28947967 0.91179982\n",
      " 0.74448144 1.28947967]\n",
      "RL\n",
      "index: 0\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1541 - accuracy: 0.9369/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1514 - accuracy: 0.9381/n\n",
      "reward: 0.7767495584807239\n",
      "n: [2. 1. 2. 1. 1. 2. 3. 3. 2. 1. 3. 2. 1. 3. 4. 1. 2. 4. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.         0.         0.52534516\n",
      " 0.40248439 0.67524485 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.62474723 0.         0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.29309623 1.82871422 1.29309623 1.82871422 1.82871422 1.29309623\n",
      " 1.05580865 1.05580865 1.29309623 1.82871422 1.05580865 1.29309623\n",
      " 1.82871422 1.05580865 0.91435711 1.82871422 1.29309623 0.91435711\n",
      " 0.74656946 1.29309623]\n",
      "RL\n",
      "index: 1\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1424 - accuracy: 0.9440/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1535 - accuracy: 0.9400- 1s 4ms/step - /n\n",
      "reward: 0.0\n",
      "n: [2. 2. 2. 1. 1. 2. 3. 3. 2. 1. 3. 2. 1. 3. 4. 1. 2. 4. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.         0.         0.52534516\n",
      " 0.40248439 0.67524485 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.62474723 0.         0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.29662687 1.29662687 1.29662687 1.8337073  1.8337073  1.29662687\n",
      " 1.05869141 1.05869141 1.29662687 1.8337073  1.05869141 1.29662687\n",
      " 1.8337073  1.05869141 0.91685365 1.8337073  1.29662687 0.91685365\n",
      " 0.74860787 1.29662687]\n",
      "RL\n",
      "index: 3\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1485 - accuracy: 0.9414/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1495 - accuracy: 0.9414/n\n",
      "reward: 0.4049266560758126\n",
      "n: [2. 2. 2. 2. 1. 2. 3. 3. 2. 1. 3. 2. 1. 3. 4. 1. 2. 4. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.52534516\n",
      " 0.40248439 0.67524485 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.62474723 0.         0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.30007541 1.30007541 1.30007541 1.30007541 1.83858428 1.30007541\n",
      " 1.06150713 1.06150713 1.30007541 1.83858428 1.06150713 1.30007541\n",
      " 1.83858428 1.06150713 0.91929214 1.83858428 1.30007541 0.91929214\n",
      " 0.75059889 1.30007541]\n",
      "RL\n",
      "index: 4\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1478 - accuracy: 0.9400/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1547 - accuracy: 0.9345/n\n",
      "reward: 0.0\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 1. 3. 2. 1. 3. 4. 1. 2. 4. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.52534516\n",
      " 0.40248439 0.67524485 0.4911228  0.         0.76353371 0.3125655\n",
      " 0.         0.68908367 0.62474723 0.         0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.30344544 1.30344544 1.30344544 1.30344544 1.30344544 1.30344544\n",
      " 1.06425874 1.06425874 1.30344544 1.84335021 1.06425874 1.30344544\n",
      " 1.84335021 1.06425874 0.92167511 1.84335021 1.30344544 0.92167511\n",
      " 0.75254457 1.30344544]\n",
      "RL\n",
      "index: 9\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9350/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1547 - accuracy: 0.9371/n\n",
      "reward: 0.30037656456088035\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 2. 3. 2. 1. 3. 4. 1. 2. 4. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.52534516\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.76353371 0.3125655\n",
      " 0.         0.68908367 0.62474723 0.         0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.30674029 1.30674029 1.30674029 1.30674029 1.30674029 1.30674029\n",
      " 1.06694898 1.06694898 1.30674029 1.30674029 1.06694898 1.30674029\n",
      " 1.84800984 1.06694898 0.92400492 1.84800984 1.30674029 0.92400492\n",
      " 0.75444686 1.30674029]\n",
      "RL\n",
      "index: 12\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1443 - accuracy: 0.9443/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1441 - accuracy: 0.9445/n\n",
      "reward: 0.5210178550817841\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 2. 3. 2. 2. 3. 4. 1. 2. 4. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.52534516\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.76353371 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.         0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.30996311 1.30996311 1.30996311 1.30996311 1.30996311 1.30996311\n",
      " 1.0695804  1.0695804  1.30996311 1.30996311 1.0695804  1.30996311\n",
      " 1.30996311 1.0695804  0.9262838  1.85256759 1.30996311 0.9262838\n",
      " 0.75630755 1.30996311]\n",
      "RL\n",
      "index: 15\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1438 - accuracy: 0.9431/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1462 - accuracy: 0.9388/n\n",
      "reward: 0.25715960197876764\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 2. 3. 2. 2. 3. 4. 2. 2. 4. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.52534516\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.76353371 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.31311685 1.31311685 1.31311685 1.31311685 1.31311685 1.31311685\n",
      " 1.07215542 1.07215542 1.31311685 1.31311685 1.07215542 1.31311685\n",
      " 1.31311685 1.07215542 0.92851383 1.31311685 1.31311685 0.92851383\n",
      " 0.75812837 1.31311685]\n",
      "RL\n",
      "index: 5\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1590 - accuracy: 0.9362/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1533 - accuracy: 0.9398/n\n",
      "reward: 1.0715024599495717\n",
      "n: [2. 2. 2. 2. 2. 3. 3. 3. 2. 2. 3. 2. 2. 3. 4. 2. 2. 4. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.76353371 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.3162043  1.3162043  1.3162043  1.3162043  1.3162043  1.07467631\n",
      " 1.07467631 1.07467631 1.3162043  1.3162043  1.07467631 1.3162043\n",
      " 1.3162043  1.07467631 0.93069699 1.3162043  1.3162043  0.93069699\n",
      " 0.75991091 1.3162043 ]\n",
      "RL\n",
      "index: 10\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9386/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1481 - accuracy: 0.9424/n\n",
      "reward: 1.2021377191510192\n",
      "n: [2. 2. 2. 2. 2. 3. 3. 3. 2. 2. 4. 2. 2. 3. 4. 2. 2. 4. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.87318472 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.89177447\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.31922807 1.31922807 1.31922807 1.31922807 1.31922807 1.07714521\n",
      " 1.07714521 1.07714521 1.31922807 1.31922807 0.93283511 1.31922807\n",
      " 1.31922807 1.07714521 0.93283511 1.31922807 1.31922807 0.93283511\n",
      " 0.76165668 1.31922807]\n",
      "RL\n",
      "index: 17\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1618 - accuracy: 0.9362/n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    420/Unknown - 1s 3ms/step - loss: 0.1515 - accuracy: 0.9405/n\n",
      "reward: 1.5303600957351084\n",
      "n: [2. 2. 2. 2. 2. 3. 3. 3. 2. 2. 4. 2. 2. 3. 4. 2. 2. 5. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.87318472 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 1.01949159\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.32219062 1.32219062 1.32219062 1.32219062 1.32219062 1.07956412\n",
      " 1.07956412 1.07956412 1.32219062 1.32219062 0.93492995 1.32219062\n",
      " 1.32219062 1.07956412 0.93492995 1.32219062 1.32219062 0.83622677\n",
      " 0.76336711 1.32219062]\n",
      "RL\n",
      "index: 17\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9395/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1513 - accuracy: 0.9374/n\n",
      "reward: 0.8140019485207258\n",
      "n: [2. 2. 2. 2. 2. 3. 3. 3. 2. 2. 4. 2. 2. 3. 4. 2. 2. 6. 6. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.87318472 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.05267591 0.33475269]\n",
      "##############\n",
      "p: [1.32509428 1.32509428 1.32509428 1.32509428 1.32509428 1.08193495\n",
      " 1.08193495 1.08193495 1.32509428 1.32509428 0.93698315 1.32509428\n",
      " 1.32509428 1.08193495 0.93698315 1.32509428 1.32509428 0.76504354\n",
      " 0.76504354 1.32509428]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1611 - accuracy: 0.9352/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1453 - accuracy: 0.9424/n\n",
      "reward: 2.0751034265711144\n",
      "n: [2. 2. 2. 2. 2. 3. 3. 3. 2. 2. 4. 2. 2. 3. 4. 2. 2. 6. 7. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.87318472 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.19873699 0.33475269]\n",
      "##############\n",
      "p: [1.32794126 1.32794126 1.32794126 1.32794126 1.32794126 1.0842595\n",
      " 1.0842595  1.0842595  1.32794126 1.32794126 0.93899627 1.32794126\n",
      " 1.32794126 1.0842595  0.93899627 1.32794126 1.32794126 0.76668724\n",
      " 0.70981446 1.32794126]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1541 - accuracy: 0.9369/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1449 - accuracy: 0.9440/n\n",
      "reward: 1.41487428950911\n",
      "n: [2. 2. 2. 2. 2. 3. 3. 3. 2. 2. 4. 2. 2. 3. 4. 2. 2. 6. 8. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.87318472 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.22575415 0.33475269]\n",
      "##############\n",
      "p: [1.33073364 1.33073364 1.33073364 1.33073364 1.33073364 1.08653946\n",
      " 1.08653946 1.08653946 1.33073364 1.33073364 0.94097078 1.33073364\n",
      " 1.33073364 1.08653946 0.94097078 1.33073364 1.33073364 0.76829942\n",
      " 0.66536682 1.33073364]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1571 - accuracy: 0.9324/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1400 - accuracy: 0.9433/n\n",
      "reward: 2.2035107844137753\n",
      "n: [2. 2. 2. 2. 2. 3. 3. 3. 2. 2. 4. 2. 2. 3. 4. 2. 2. 6. 9. 2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.87318472 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.33439378 0.33475269]\n",
      "##############\n",
      "p: [1.33347338 1.33347338 1.33347338 1.33347338 1.33347338 1.08877645\n",
      " 1.08877645 1.08877645 1.33347338 1.33347338 0.94290807 1.33347338\n",
      " 1.33347338 1.08877645 0.94290807 1.33347338 1.33347338 0.76988121\n",
      " 0.62860538 1.33347338]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1508 - accuracy: 0.9395/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1459 - accuracy: 0.9424/n\n",
      "reward: 0.9949299476270209\n",
      "n: [ 2.  2.  2.  2.  2.  3.  3.  3.  2.  2.  4.  2.  2.  3.  4.  2.  2.  6.\n",
      " 10.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.87318472 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.30044739 0.33475269]\n",
      "##############\n",
      "p: [1.33616235 1.33616235 1.33616235 1.33616235 1.33616235 1.09097199\n",
      " 1.09097199 1.09097199 1.33616235 1.33616235 0.94480946 1.33616235\n",
      " 1.33616235 1.09097199 0.94480946 1.33616235 1.33616235 0.77143369\n",
      " 0.59754997 1.33616235]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1446 - accuracy: 0.9431/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1536 - accuracy: 0.9376/n\n",
      "reward: 0.0\n",
      "n: [ 2.  2.  2.  2.  2.  3.  3.  3.  2.  2.  4.  2.  2.  3.  4.  2.  2.  6.\n",
      " 11.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.4911228  0.15018828 0.87318472 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.1822249  0.33475269]\n",
      "##############\n",
      "p: [1.33880233 1.33880233 1.33880233 1.33880233 1.33880233 1.09312753\n",
      " 1.09312753 1.09312753 1.33880233 1.33880233 0.94667621 1.33880233\n",
      " 1.33880233 1.09312753 0.94667621 1.33880233 1.33880233 0.77295789\n",
      " 0.57086723 1.33880233]\n",
      "RL\n",
      "index: 8\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1501 - accuracy: 0.9374/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1507 - accuracy: 0.9393/n\n",
      "reward: 0.4425569652694773\n",
      "n: [ 2.  2.  2.  2.  2.  3.  3.  3.  3.  2.  4.  2.  2.  3.  4.  2.  2.  6.\n",
      " 11.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.47493419 0.15018828 0.87318472 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.1822249  0.33475269]\n",
      "##############\n",
      "p: [1.341395   1.341395   1.341395   1.341395   1.341395   1.09524443\n",
      " 1.09524443 1.09524443 1.09524443 1.341395   0.9485095  1.341395\n",
      " 1.341395   1.09524443 0.9485095  1.341395   1.341395   0.77445477\n",
      " 0.57197275 1.341395  ]\n",
      "RL\n",
      "index: 10\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1475 - accuracy: 0.9414/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1478 - accuracy: 0.9417/n\n",
      "reward: 0.4779482846913342\n",
      "n: [ 2.  2.  2.  2.  2.  3.  3.  3.  3.  2.  5.  2.  2.  3.  4.  2.  2.  6.\n",
      " 11.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.7073976\n",
      " 0.40248439 0.67524485 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.1822249  0.33475269]\n",
      "##############\n",
      "p: [1.34394195 1.34394195 1.34394195 1.34394195 1.34394195 1.09732401\n",
      " 1.09732401 1.09732401 1.09732401 1.34394195 0.84998352 1.34394195\n",
      " 1.34394195 1.09732401 0.95031047 1.34394195 1.34394195 0.77592525\n",
      " 0.57305877 1.34394195]\n",
      "RL\n",
      "index: 5\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1525 - accuracy: 0.9410/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1467 - accuracy: 0.9440/n\n",
      "reward: 1.0773707804517136\n",
      "n: [ 2.  2.  2.  2.  2.  4.  3.  3.  3.  2.  5.  2.  2.  3.  4.  2.  2.  6.\n",
      " 11.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.79989089\n",
      " 0.40248439 0.67524485 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.68908367 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.1822249  0.33475269]\n",
      "##############\n",
      "p: [1.34644471 1.34644471 1.34644471 1.34644471 1.34644471 0.95208018\n",
      " 1.0993675  1.0993675  1.0993675  1.34644471 0.85156641 1.34644471\n",
      " 1.34644471 1.0993675  0.95208018 1.34644471 1.34644471 0.77737022\n",
      " 0.57412595 1.34644471]\n",
      "RL\n",
      "index: 13\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1481 - accuracy: 0.9419/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1509 - accuracy: 0.9395/n\n",
      "reward: 0.2197380070143219\n",
      "n: [ 2.  2.  2.  2.  2.  4.  3.  3.  3.  2.  5.  2.  2.  4.  4.  2.  2.  6.\n",
      " 11.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.79989089\n",
      " 0.40248439 0.67524485 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.1822249  0.33475269]\n",
      "##############\n",
      "p: [1.34890472 1.34890472 1.34890472 1.34890472 1.34890472 0.95381967\n",
      " 1.10137609 1.10137609 1.10137609 1.34890472 0.85312225 1.34890472\n",
      " 1.34890472 0.95381967 0.95381967 1.34890472 1.34890472 0.7787905\n",
      " 0.5751749  1.34890472]\n",
      "RL\n",
      "index: 7\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1444 - accuracy: 0.9467/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1503 - accuracy: 0.9402/n\n",
      "reward: 0.0\n",
      "n: [ 2.  2.  2.  2.  2.  4.  3.  4.  3.  2.  5.  2.  2.  4.  4.  2.  2.  6.\n",
      " 11.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.79989089\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.98524332\n",
      " 1.1822249  0.33475269]\n",
      "##############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [1.35132335 1.35132335 1.35132335 1.35132335 1.35132335 0.95552991\n",
      " 1.1033509  0.95552991 1.1033509  1.35132335 0.85465193 1.35132335\n",
      " 1.35132335 0.95552991 0.95552991 1.35132335 1.35132335 0.7801869\n",
      " 0.57620621 1.35132335]\n",
      "RL\n",
      "index: 17\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1490 - accuracy: 0.9431/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1556 - accuracy: 0.9381/n\n",
      "reward: 0.0\n",
      "n: [ 2.  2.  2.  2.  2.  4.  3.  4.  3.  2.  5.  2.  2.  4.  4.  2.  2.  7.\n",
      " 11.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.79989089\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.1822249  0.33475269]\n",
      "##############\n",
      "p: [1.35370193 1.35370193 1.35370193 1.35370193 1.35370193 0.95721181\n",
      " 1.105293   0.95721181 1.105293   1.35370193 0.85615627 1.35370193\n",
      " 1.35370193 0.95721181 0.95721181 1.35370193 1.35370193 0.72358412\n",
      " 0.57722044 1.35370193]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1449 - accuracy: 0.9438/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1492 - accuracy: 0.9395/n\n",
      "reward: 0.06876280614995191\n",
      "n: [ 2.  2.  2.  2.  2.  4.  3.  4.  3.  2.  5.  2.  2.  4.  4.  2.  2.  7.\n",
      " 12.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.79989089\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.33475269]\n",
      "##############\n",
      "p: [1.3560417  1.3560417  1.3560417  1.3560417  1.3560417  0.95886628\n",
      " 1.10720341 0.95886628 1.10720341 1.3560417  0.85763607 1.3560417\n",
      " 1.3560417  0.95886628 0.95886628 1.3560417  1.3560417  0.72483478\n",
      " 0.55360171 1.3560417 ]\n",
      "RL\n",
      "index: 5\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1548 - accuracy: 0.9374/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9362/n\n",
      "reward: 0.7103658855005408\n",
      "n: [ 2.  2.  2.  2.  2.  5.  3.  4.  3.  2.  5.  2.  2.  4.  4.  2.  2.  7.\n",
      " 12.  2.]\n",
      "mu: [0.38837478 0.         0.36234936 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.33475269]\n",
      "##############\n",
      "p: [1.35834386 1.35834386 1.35834386 1.35834386 1.35834386 0.85909209\n",
      " 1.10908312 0.96049415 1.10908312 1.35834386 0.85909209 1.35834386\n",
      " 1.35834386 0.96049415 0.96049415 1.35834386 1.35834386 0.72606533\n",
      " 0.55454156 1.35834386]\n",
      "RL\n",
      "index: 0\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1478 - accuracy: 0.9410/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1535 - accuracy: 0.940 - 1s 3ms/step - loss: 0.1535 - accuracy: 0.9402/n\n",
      "reward: 0.0\n",
      "n: [ 3.  2.  2.  2.  2.  5.  3.  4.  3.  2.  5.  2.  2.  4.  4.  2.  2.  7.\n",
      " 12.  2.]\n",
      "mu: [0.25891652 0.         0.36234936 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.33475269]\n",
      "##############\n",
      "p: [1.11093305 1.36060955 1.36060955 1.36060955 1.36060955 0.86052504\n",
      " 1.11093305 0.96209624 1.11093305 1.36060955 0.86052504 1.36060955\n",
      " 1.36060955 0.96209624 0.96209624 1.36060955 1.36060955 0.7272764\n",
      " 0.55546652 1.36060955]\n",
      "RL\n",
      "index: 2\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9329/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9393/n\n",
      "reward: 1.033200122680727\n",
      "n: [ 3.  2.  3.  2.  2.  5.  3.  4.  3.  2.  5.  2.  2.  4.  4.  2.  2.  7.\n",
      " 12.  2.]\n",
      "mu: [0.25891652 0.         0.58596628 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.33475269]\n",
      "##############\n",
      "p: [1.11275409 1.36283986 1.11275409 1.36283986 1.36283986 0.86193561\n",
      " 1.11275409 0.96367331 1.11275409 1.36283986 0.86193561 1.36283986\n",
      " 1.36283986 0.96367331 0.96367331 1.36283986 1.36283986 0.72846855\n",
      " 0.55637704 1.36283986]\n",
      "RL\n",
      "index: 2\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1532 - accuracy: 0.9367/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1471 - accuracy: 0.9405/n\n",
      "reward: 1.104554114259026\n",
      "n: [ 3.  2.  4.  2.  2.  5.  3.  4.  3.  2.  5.  2.  2.  4.  4.  2.  2.  7.\n",
      " 12.  2.]\n",
      "mu: [0.25891652 0.         0.71561324 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.33475269]\n",
      "##############\n",
      "p: [1.1145471  1.36503585 0.9652261  1.36503585 1.36503585 0.86332447\n",
      " 1.1145471  0.9652261  1.1145471  1.36503585 0.86332447 1.36503585\n",
      " 1.36503585 0.9652261  0.9652261  1.36503585 1.36503585 0.72964235\n",
      " 0.55727355 1.36503585]\n",
      "RL\n",
      "index: 19\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1543 - accuracy: 0.9348/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1523 - accuracy: 0.9388/n\n",
      "reward: 0.7004976076395465\n",
      "n: [ 3.  2.  4.  2.  2.  5.  3.  4.  3.  2.  5.  2.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.71561324 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.1163129  1.36719849 0.96675533 1.36719849 1.36719849 0.86469225\n",
      " 1.1163129  0.96675533 1.1163129  1.36719849 0.86469225 1.36719849\n",
      " 1.36719849 0.96675533 0.96675533 1.36719849 1.36719849 0.73079833\n",
      " 0.55815645 1.1163129 ]\n",
      "RL\n",
      "index: 2\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9390/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1446 - accuracy: 0.9445/n\n",
      "reward: 1.1839611470266933\n",
      "n: [ 3.  2.  5.  2.  2.  5.  3.  4.  3.  2.  5.  2.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.80928282 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.3125655\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.11805225 1.36932876 0.86603955 1.36932876 1.36932876 0.86603955\n",
      " 1.11805225 0.96826165 1.11805225 1.36932876 0.86603955 1.36932876\n",
      " 1.36932876 0.96826165 0.96826165 1.36932876 1.36932876 0.73193701\n",
      " 0.55902613 1.11805225]\n",
      "RL\n",
      "index: 11\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1562 - accuracy: 0.9388/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1384 - accuracy: 0.9481/n\n",
      "reward: 2.27742229351896\n",
      "n: [ 3.  2.  5.  2.  2.  5.  3.  4.  3.  2.  5.  3.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.80928282 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.96751776\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.11976593 1.37142757 0.86736696 1.37142757 1.37142757 0.86736696\n",
      " 1.11976593 0.96974574 1.11976593 1.37142757 0.86736696 1.11976593\n",
      " 1.37142757 0.96974574 0.96974574 1.37142757 1.37142757 0.73305887\n",
      " 0.55988296 1.11976593]\n",
      "RL\n",
      "index: 11\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9388/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1450 - accuracy: 0.9414/n\n",
      "reward: 1.2115667237303558\n",
      "n: [ 3.  2.  5.  2.  2.  5.  3.  4.  3.  2.  5.  4.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.80928282 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 1.02853\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.12145463 1.3734958  0.86867502 1.3734958  1.3734958  0.86867502\n",
      " 1.12145463 0.9712082  1.12145463 1.3734958  0.86867502 0.9712082\n",
      " 1.3734958  0.9712082  0.9712082  1.3734958  1.3734958  0.73416439\n",
      " 0.56072731 1.12145463]\n",
      "RL\n",
      "index: 11\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1449 - accuracy: 0.9417/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1424 - accuracy: 0.9445/n\n",
      "reward: 0.7468015492957498\n",
      "n: [ 3.  2.  5.  2.  2.  5.  3.  4.  3.  2.  5.  5.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.80928282 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.97218431\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.12311905 1.3755343  0.86996428 1.3755343  1.3755343  0.86996428\n",
      " 1.12311905 0.97264963 1.12311905 1.3755343  0.86996428 0.86996428\n",
      " 1.3755343  0.97264963 0.97264963 1.3755343  1.3755343  0.73525401\n",
      " 0.56155953 1.12311905]\n",
      "RL\n",
      "index: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    420/Unknown - 1s 4ms/step - loss: 0.1525 - accuracy: 0.9410/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1554 - accuracy: 0.9379/n\n",
      "reward: 0.20820587239272725\n",
      "n: [ 3.  2.  5.  2.  2.  5.  3.  4.  3.  2.  5.  6.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.80928282 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.84485457\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.12475985 1.37754386 0.87123524 1.37754386 1.37754386 0.87123524\n",
      " 1.12475985 0.97407061 1.12475985 1.37754386 0.87123524 0.79532532\n",
      " 1.37754386 0.97407061 0.97407061 1.37754386 1.37754386 0.73632817\n",
      " 0.56237993 1.12475985]\n",
      "RL\n",
      "index: 2\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1492 - accuracy: 0.9374/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1496 - accuracy: 0.9374/n\n",
      "reward: 0.46686298819397465\n",
      "n: [ 3.  2.  6.  2.  2.  5.  3.  4.  3.  2.  5.  6.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.79413743 0.84485457\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.12637767 1.37952528 0.79646929 1.37952528 1.37952528 0.87248839\n",
      " 1.12637767 0.97547168 1.12637767 1.37952528 0.87248839 0.79646929\n",
      " 1.37952528 0.97547168 0.97547168 1.37952528 1.37952528 0.73738728\n",
      " 0.56318884 1.12637767]\n",
      "RL\n",
      "index: 10\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1493 - accuracy: 0.9362/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1545 - accuracy: 0.9360/n\n",
      "reward: 0.0\n",
      "n: [ 3.  2.  6.  2.  2.  5.  3.  4.  3.  2.  6.  6.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.78198589\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.66178119 0.84485457\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.12797311 1.38147929 0.79759744 1.38147929 1.38147929 0.87372422\n",
      " 1.12797311 0.97685337 1.12797311 1.38147929 0.79759744 0.79759744\n",
      " 1.38147929 0.97685337 0.97685337 1.38147929 1.38147929 0.73843174\n",
      " 0.56398656 1.12797311]\n",
      "RL\n",
      "index: 5\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9360/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1489 - accuracy: 0.9445/n\n",
      "reward: 1.245008122900065\n",
      "n: [ 3.  2.  6.  2.  2.  6.  3.  4.  3.  2.  6.  6.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.85915626\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.66178119 0.84485457\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.12954677 1.38340661 0.79871018 1.38340661 1.38340661 0.79871018\n",
      " 1.12954677 0.9782162  1.12954677 1.38340661 0.79871018 0.79871018\n",
      " 1.38340661 0.9782162  0.9782162  1.38340661 1.38340661 0.73946194\n",
      " 0.56477338 1.12954677]\n",
      "RL\n",
      "index: 5\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1533 - accuracy: 0.9381/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1480 - accuracy: 0.9390/n\n",
      "reward: 1.0286870827659995\n",
      "n: [ 3.  2.  6.  2.  2.  7.  3.  4.  3.  2.  6.  6.  2.  4.  4.  2.  2.  7.\n",
      " 12.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.88337495\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.66178119 0.84485457\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.08943639 0.45666766]\n",
      "##############\n",
      "p: [1.1310992  1.38530794 0.79980791 1.38530794 1.38530794 0.74047824\n",
      " 1.1310992  0.97956064 1.1310992  1.38530794 0.79980791 0.79980791\n",
      " 1.38530794 0.97956064 0.97956064 1.38530794 1.38530794 0.74047824\n",
      " 0.5655496  1.1310992 ]\n",
      "RL\n",
      "index: 18\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1447 - accuracy: 0.9440/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1603 - accuracy: 0.9355/n\n",
      "reward: 0.0\n",
      "n: [ 3.  2.  6.  2.  2.  7.  3.  4.  3.  2.  6.  6.  2.  4.  4.  2.  2.  7.\n",
      " 13.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.88337495\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.66178119 0.84485457\n",
      " 0.26050893 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.45666766]\n",
      "##############\n",
      "p: [1.13263094 1.38718394 0.80089102 1.38718394 1.38718394 0.74148101\n",
      " 1.13263094 0.98088717 1.13263094 1.38718394 0.80089102 0.80089102\n",
      " 1.38718394 0.98088717 0.98088717 1.38718394 1.38718394 0.74148101\n",
      " 0.54409831 1.13263094]\n",
      "RL\n",
      "index: 12\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1480 - accuracy: 0.9431/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9429/n\n",
      "reward: 0.16039491502756698\n",
      "n: [ 3.  2.  6.  2.  2.  7.  3.  4.  3.  2.  6.  6.  3.  4.  4.  2.  2.  7.\n",
      " 13.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.88337495\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.66178119 0.84485457\n",
      " 0.22713759 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.45666766]\n",
      "##############\n",
      "p: [1.13414253 1.38903525 0.80195988 1.38903525 1.38903525 0.74247057\n",
      " 1.13414253 0.98219624 1.13414253 1.38903525 0.80195988 0.80195988\n",
      " 1.13414253 0.98219624 0.98219624 1.38903525 1.38903525 0.74247057\n",
      " 0.54482445 1.13414253]\n",
      "RL\n",
      "index: 11\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1506 - accuracy: 0.9364/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1480 - accuracy: 0.9412/n\n",
      "reward: 0.7533602572986543\n",
      "n: [ 3.  2.  6.  2.  2.  7.  3.  4.  3.  2.  6.  7.  3.  4.  4.  2.  2.  7.\n",
      " 13.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.88337495\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.45666766]\n",
      "##############\n",
      "p: [1.13563446 1.39086248 0.80301483 1.39086248 1.39086248 0.74344727\n",
      " 1.13563446 0.98348829 1.13563446 1.39086248 0.80301483 0.74344727\n",
      " 1.13563446 0.98348829 0.98348829 1.39086248 1.39086248 0.74344727\n",
      " 0.54554115 1.13563446]\n",
      "RL\n",
      "index: 5\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1639 - accuracy: 0.9355/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1543 - accuracy: 0.9386/n\n",
      "reward: 1.4536654109390281\n",
      "n: [ 3.  2.  6.  2.  2.  8.  3.  4.  3.  2.  6.  7.  3.  4.  4.  2.  2.  7.\n",
      " 13.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.95466126\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.45666766]\n",
      "##############\n",
      "p: [1.13710722 1.39266624 0.80405623 1.39266624 1.39266624 0.69633312\n",
      " 1.13710722 0.98476374 1.13710722 1.39266624 0.80405623 0.74441142\n",
      " 1.13710722 0.98476374 0.98476374 1.39266624 1.39266624 0.74441142\n",
      " 0.54624864 1.13710722]\n",
      "RL\n",
      "index: 5\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1502 - accuracy: 0.9440/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1508 - accuracy: 0.9443/n\n",
      "reward: 0.4409803324046414\n",
      "n: [ 3.  2.  6.  2.  2.  9.  3.  4.  3.  2.  6.  7.  3.  4.  4.  2.  2.  7.\n",
      " 13.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.47493419 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.45666766]\n",
      "##############\n",
      "p: [1.13856128 1.39444708 0.8050844  1.39444708 1.39444708 0.65734866\n",
      " 1.13856128 0.98602299 1.13856128 1.39444708 0.8050844  0.74536332\n",
      " 1.13856128 0.98602299 0.98602299 1.39444708 1.39444708 0.74536332\n",
      " 0.54694715 1.13856128]\n",
      "RL\n",
      "index: 8\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9426/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1537 - accuracy: 0.9405/n\n",
      "reward: 0.0\n",
      "n: [ 3.  2.  6.  2.  2.  9.  3.  4.  4.  2.  6.  7.  3.  4.  4.  2.  2.  7.\n",
      " 13.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.62474723 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.45666766]\n",
      "##############\n",
      "p: [1.13999708 1.39620557 0.80609966 1.39620557 1.39620557 0.65817762\n",
      " 1.13999708 0.98726643 0.98726643 1.39620557 0.80609966 0.74630327\n",
      " 1.13999708 0.98726643 0.98726643 1.39620557 1.39620557 0.74630327\n",
      " 0.54763688 1.13999708]\n",
      "RL\n",
      "index: 14\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1523 - accuracy: 0.9452/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1577 - accuracy: 0.9312/n\n",
      "reward: 0.0\n",
      "n: [ 3.  2.  6.  2.  2.  9.  3.  4.  4.  2.  6.  7.  3.  4.  5.  2.  2.  7.\n",
      " 13.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.20246333 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.49979778 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.45666766]\n",
      "##############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [1.14141506 1.39794224 0.80710233 1.39794224 1.39794224 0.65899629\n",
      " 1.14141506 0.98849444 0.98849444 1.39794224 0.80710233 0.74723156\n",
      " 1.14141506 0.98849444 0.8841363  1.39794224 1.39794224 0.74723156\n",
      " 0.54831806 1.14141506]\n",
      "RL\n",
      "index: 3\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9388/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1465 - accuracy: 0.9407/n\n",
      "reward: 1.0585650982019241\n",
      "n: [ 3.  2.  6.  3.  2.  9.  3.  4.  4.  2.  6.  7.  3.  4.  5.  2.  2.  7.\n",
      " 13.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.48783058 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.49979778 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.45666766]\n",
      "##############\n",
      "p: [1.14281564 1.3996576  0.80809269 1.14281564 1.3996576  0.65980492\n",
      " 1.14281564 0.98970738 0.98970738 1.3996576  0.80809269 0.74814846\n",
      " 1.14281564 0.98970738 0.88522119 1.3996576  1.3996576  0.74814846\n",
      " 0.54899088 1.14281564]\n",
      "RL\n",
      "index: 3\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1473 - accuracy: 0.9433/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1578 - accuracy: 0.9379/n\n",
      "reward: 0.0\n",
      "n: [ 3.  2.  6.  4.  2.  9.  3.  4.  4.  2.  6.  7.  3.  4.  5.  2.  2.  7.\n",
      " 13.  3.]\n",
      "mu: [0.25891652 0.         0.75221285 0.36587294 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.49979778 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.45666766]\n",
      "##############\n",
      "p: [1.14419923 1.40135214 0.80907104 0.9909056  1.40135214 0.66060374\n",
      " 1.14419923 0.9909056  0.9909056  1.40135214 0.80907104 0.74905423\n",
      " 1.14419923 0.9909056  0.88629291 1.40135214 1.40135214 0.74905423\n",
      " 0.54965553 1.14419923]\n",
      "RL\n",
      "index: 19\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1574 - accuracy: 0.9345/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9412/n\n",
      "reward: 1.101121044041758\n",
      "n: [ 3.  2.  6.  4.  2.  9.  3.  4.  4.  2.  6.  7.  3.  4.  5.  2.  2.  7.\n",
      " 13.  4.]\n",
      "mu: [0.25891652 0.         0.75221285 0.36587294 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.49979778 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.61778101]\n",
      "##############\n",
      "p: [1.14556622 1.40302635 0.81003764 0.99208945 1.40302635 0.66139297\n",
      " 1.14556622 0.99208945 0.99208945 1.40302635 0.81003764 0.74994913\n",
      " 1.14556622 0.99208945 0.88735178 1.40302635 1.40302635 0.74994913\n",
      " 0.55031221 0.99208945]\n",
      "RL\n",
      "index: 19\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1434 - accuracy: 0.9429/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1535 - accuracy: 0.9433/n\n",
      "reward: 0.0\n",
      "n: [ 3.  2.  6.  4.  2.  9.  3.  4.  4.  2.  6.  7.  3.  4.  5.  2.  2.  7.\n",
      " 13.  5.]\n",
      "mu: [0.25891652 0.         0.75221285 0.36587294 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.49979778 0.1285798  0.18702636 0.84449427\n",
      " 1.00563359 0.49422481]\n",
      "##############\n",
      "p: [1.14691698 1.40468069 0.81099278 0.99325924 1.40468069 0.66217283\n",
      " 1.14691698 0.99325924 0.99325924 1.40468069 0.81099278 0.75083341\n",
      " 1.14691698 0.99325924 0.88839808 1.40468069 1.40468069 0.75083341\n",
      " 0.5509611  0.88839808]\n",
      "RL\n",
      "index: 17\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1434 - accuracy: 0.9402/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1502 - accuracy: 0.9390/n\n",
      "reward: 0.0\n",
      "n: [ 3.  2.  6.  4.  2.  9.  3.  4.  4.  2.  6.  7.  3.  4.  5.  2.  2.  8.\n",
      " 13.  5.]\n",
      "mu: [0.25891652 0.         0.75221285 0.36587294 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.49979778 0.1285798  0.18702636 0.73893249\n",
      " 1.00563359 0.49422481]\n",
      "##############\n",
      "p: [1.14825189 1.40631561 0.8119367  0.99441531 1.40631561 0.66294354\n",
      " 1.14825189 0.99441531 0.99441531 1.40631561 0.8119367  0.75170731\n",
      " 1.14825189 0.99441531 0.88943209 1.40631561 1.40631561 0.70315781\n",
      " 0.55160237 0.88943209]\n",
      "RL\n",
      "index: 16\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1470 - accuracy: 0.9405/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1578 - accuracy: 0.9390/n\n",
      "reward: 0.0\n",
      "n: [ 3.  2.  6.  4.  2.  9.  3.  4.  4.  2.  6.  7.  3.  4.  5.  2.  3.  8.\n",
      " 13.  5.]\n",
      "mu: [0.25891652 0.         0.75221285 0.36587294 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.83178396\n",
      " 0.22713759 0.57174725 0.49979778 0.1285798  0.12468424 0.73893249\n",
      " 1.00563359 0.49422481]\n",
      "##############\n",
      "p: [1.14957129 1.40793154 0.81286966 0.99555794 1.40793154 0.66370529\n",
      " 1.14957129 0.99555794 0.99555794 1.40793154 0.81286966 0.75257107\n",
      " 1.14957129 0.99555794 0.89045409 1.40793154 1.14957129 0.70396577\n",
      " 0.55223619 0.89045409]\n",
      "RL\n",
      "index: 11\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1559 - accuracy: 0.9390/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9405/n\n",
      "reward: 0.35567804493863664\n",
      "n: [ 3.  2.  6.  4.  2.  9.  3.  4.  4.  2.  6.  8.  3.  4.  5.  2.  3.  8.\n",
      " 13.  5.]\n",
      "mu: [0.25891652 0.         0.75221285 0.36587294 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.77227072\n",
      " 0.22713759 0.57174725 0.49979778 0.1285798  0.12468424 0.73893249\n",
      " 1.00563359 0.49422481]\n",
      "##############\n",
      "p: [1.15087553 1.40952891 0.81379189 0.99668745 1.40952891 0.6644583\n",
      " 1.15087553 0.99668745 0.99668745 1.40952891 0.81379189 0.70476445\n",
      " 1.15087553 0.99668745 0.89146435 1.40952891 1.15087553 0.70476445\n",
      " 0.55286272 0.89146435]\n",
      "RL\n",
      "index: 13\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1501 - accuracy: 0.9424/n\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1430 - accuracy: 0.9433/n\n",
      "reward: 1.213252028536296\n",
      "n: [ 3.  2.  6.  4.  2.  9.  3.  4.  4.  2.  6.  8.  3.  5.  5.  2.  3.  8.\n",
      " 13.  5.]\n",
      "mu: [0.25891652 0.         0.75221285 0.36587294 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.77227072\n",
      " 0.22713759 0.70004821 0.49979778 0.1285798  0.12468424 0.73893249\n",
      " 1.00563359 0.49422481]\n",
      "##############\n",
      "p: [1.15216494 1.4111081  0.81470364 0.99780411 1.4111081  0.66520274\n",
      " 1.15216494 0.99780411 0.99780411 1.4111081  0.81470364 0.70555405\n",
      " 1.15216494 0.89246313 0.89246313 1.4111081  1.15216494 0.70555405\n",
      " 0.55348213 0.89246313]\n",
      "RL\n",
      "index: 13\n",
      "    420/Unknown - 1s 4ms/step - loss: 0.1519 - accuracy: 0.9390/n\n",
      "    420/Unknown - 2s 4ms/step - loss: 0.1514 - accuracy: 0.9390/n\n",
      "reward: 0.5491707575219213\n",
      "n: [ 3.  2.  6.  4.  2.  9.  3.  4.  4.  2.  6.  8.  3.  6.  5.  2.  3.  8.\n",
      " 13.  5.]\n",
      "mu: [0.25891652 0.         0.75221285 0.36587294 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.77227072\n",
      " 0.22713759 0.67490197 0.49979778 0.1285798  0.12468424 0.73893249\n",
      " 1.00563359 0.49422481]\n",
      "##############\n",
      "p: [1.15343984 1.41266953 0.81560513 0.9989082  1.41266953 0.6659388\n",
      " 1.15343984 0.9989082  0.9989082  1.41266953 0.81560513 0.70633476\n",
      " 1.15343984 0.81560513 0.89345066 1.41266953 1.15343984 0.70633476\n",
      " 0.55409458 0.89345066]\n",
      "RL\n",
      "index: 2\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9331/n\n",
      "    420/Unknown - 1s 3ms/step - loss: 0.1446 - accuracy: 0.9410/n\n",
      "reward: 1.7721504212129837\n",
      "n: [ 3.  2.  7.  4.  2.  9.  3.  4.  4.  2.  6.  8.  3.  6.  5.  2.  3.  8.\n",
      " 13.  5.]\n",
      "mu: [0.25891652 0.         0.89791822 0.36587294 0.         0.8975856\n",
      " 0.40248439 0.50643364 0.35620064 0.15018828 0.66178119 0.77227072\n",
      " 0.22713759 0.67490197 0.49979778 0.1285798  0.12468424 0.73893249\n",
      " 1.00563359 0.49422481]\n",
      "##############\n"
     ]
    }
   ],
   "source": [
    "T = 100\n",
    "W = model.layers[-2].get_weights()\n",
    "n = np.zeros(20)\n",
    "mu = np.zeros_like(n)\n",
    "threshold = 0.005\n",
    "norm_const=0.01\n",
    "for i in range(1, T):\n",
    "    #select random train data for comparison\n",
    "    data = select_random_data(train_data)\n",
    "    \n",
    "    #selecting index exploration/exploitation\n",
    "    if np.where(n==0)[0].size == 0:\n",
    "        index = UCB1(mu, n, i)\n",
    "        print(\"RL\")\n",
    "    else:\n",
    "        index = np.where(n==0)[0][0]\n",
    "    \n",
    "    print(\"index:\", index)\n",
    "    \n",
    "    #evaluating main model\n",
    "    loss_base = model.evaluate(data)[0]\n",
    "    print(\"/n\")\n",
    "\n",
    "    \n",
    "    #setting selected node to zero and evaluating again\n",
    "    W_ = np.copy(W)\n",
    "    W_[0][:, index] = 0\n",
    "    model.layers[-3].set_weights(W_)\n",
    "    loss = model.evaluate(data)[0]\n",
    "    print(\"/n\")\n",
    "    \n",
    "    #calculating delta and reward\n",
    "    delta = loss_base - loss\n",
    "    reward = max(0, threshold + delta)/norm_const\n",
    "    print(\"reward:\", reward)\n",
    "    \n",
    "    #updating number of visiting the node and the average reward\n",
    "    n[index] = n[index]+1\n",
    "    print(\"n:\", n)\n",
    "    mu[index] = ((n[index]-1)/n[index])*mu[index] + (1/n[index])*reward\n",
    "    print(\"mu:\", mu)\n",
    "    print(\"##############\")\n",
    "    #initializing the layer to the original trained weights for next round\n",
    "    model.layers[-3].set_weights(W)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  2.,  7.,  4.,  2.,  9.,  3.,  4.,  4.,  2.,  6.,  8.,  3.,\n",
       "        6.,  5.,  2.,  3.,  8., 13.,  5.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4, 16, 15,  9, 12,  0,  8,  3,  6, 19, 14,  7, 10, 13, 17, 11,\n",
       "        5,  2, 18])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    885/Unknown - 2s 2ms/step - loss: 0.1561 - accuracy: 0.9364"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15614040915702262, 0.9363842]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W_ = np.copy(W)\n",
    "# # W_[0][:, 18] = 0\n",
    "# # W_[0][:, 2] = 0\n",
    "# # W_[:, 13] = 0\n",
    "# model.layers[-3].set_weights(W_)\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.70710678 0.57735027 0.5        0.4472136  0.40824829\n",
      " 0.37796447 0.35355339 0.33333333 0.31622777 0.30151134 0.28867513\n",
      " 0.2773501  0.26726124 0.25819889 0.25       0.24253563 0.23570226\n",
      " 0.22941573 0.2236068  0.21821789 0.21320072 0.20851441 0.20412415\n",
      " 0.2        0.19611614 0.19245009 0.18898224 0.18569534 0.18257419\n",
      " 0.1796053  0.1767767  0.17407766 0.17149859 0.16903085 0.16666667\n",
      " 0.16439899 0.16222142 0.16012815 0.15811388 0.15617376 0.15430335\n",
      " 0.15249857 0.15075567 0.1490712  0.14744196 0.14586499 0.14433757\n",
      " 0.14285714 0.14142136 0.14002801 0.13867505 0.13736056 0.13608276\n",
      " 0.13483997 0.13363062 0.13245324 0.13130643 0.13018891 0.12909944\n",
      " 0.12803688 0.12700013 0.12598816 0.125      0.12403473 0.12309149\n",
      " 0.12216944 0.12126781 0.12038585 0.11952286 0.11867817 0.11785113\n",
      " 0.11704115 0.11624764 0.11547005 0.11470787 0.11396058 0.1132277\n",
      " 0.11250879 0.1118034  0.11111111 0.11043153 0.10976426 0.10910895\n",
      " 0.10846523 0.10783277 0.10721125 0.10660036 0.10599979 0.10540926\n",
      " 0.10482848 0.10425721 0.10369517 0.10314212 0.10259784 0.10206207\n",
      " 0.10153462 0.10101525 0.10050378 0.1       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8d3c61ea90>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.arange(100)+1\n",
    "t = sum(a)\n",
    "p=np.sqrt(2*np.log10(t)/a)\n",
    "pp = p/p.max()\n",
    "print(pp)\n",
    "plt.plot(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6130902 , 1.93131806, 1.65854132, 1.93131806, 1.60969079])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p+m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-1f9a7cd9affb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'argmax' is not defined"
     ]
    }
   ],
   "source": [
    "mu[argmax(mu)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,3,2,1,1,1])\n",
    "a[2] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers[-3].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
