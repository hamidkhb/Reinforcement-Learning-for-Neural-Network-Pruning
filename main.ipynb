{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import importlib\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SGECluster\n",
    "import socket\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, MaxPool2D, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fe/khodabakhshandeh/anaconda3/envs/main-env/lib/python3.7/site-packages/distributed/dashboard/core.py:79: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.66.20.3:37086</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.66.20.3:34181/status' target='_blank'>http://10.66.20.3:34181/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>540.49 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.66.20.3:37086' processes=1 threads=4, memory=540.49 GB>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hostname = socket.gethostname()\n",
    "n_workers = 1\n",
    "n_cores = 4\n",
    "\n",
    "wks2 = \"wn-wks2.fe.hhi.de\"\n",
    "gpu1 = \"wn-gpu1.fe.hhi.de\"\n",
    "gpu2 = \"wn-gpu-104-01.fe.hhi.de\"\n",
    "\n",
    "if hostname == wks2:\n",
    "    path = \"/data/cluster/projects/infineon-radar/daq_x-har/3_Walking_converted/recording-2020-01-28_11-31-55\"\n",
    "    mem = \"20G\"      # Allocated memory is critical. For this example it must be at least 16GB \n",
    "    q = \"wn-37.q\"    # Check current queue status on https://hpc-management.fe.hhi.de/wn/phpqstat/\n",
    "    \n",
    "    cluster = SGECluster(n_workers=n_workers, cores=n_cores, memory=mem,\n",
    "                        resource_spec=f\"h_vmem={mem}\", host=hostname, queue=q,\n",
    "                         job_extra=[\"-v MKL_NUM_THREADS=1,NUMEXPR_NUM_THREADS=1,OMP_NUM_THREADS=1\"])\n",
    "elif hostname in (gpu1, gpu2):\n",
    "    path = os.getcwd() + \"/data\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,3\"  # Check current status with nvidia-smi and pick GPU from 0-3\n",
    "    cluster = LocalCluster(n_workers=n_workers, threads_per_worker=n_cores, host=hostname)\n",
    "else:\n",
    "    raise ValueError(f\"{hostname} is not a supported host. Please run this example on {wks}, {gpu1} or {gpu2}.\")\n",
    "    \n",
    "\n",
    "    \n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers=n_workers)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset: tf.data.Dataset, validation_data_fraction: float):\n",
    "\n",
    "    validation_data_percent = round(validation_data_fraction * 100)\n",
    "    if not (0 <= validation_data_percent <= 100):\n",
    "        raise ValueError(\"validation data fraction must be âˆˆ [0,1]\")\n",
    "\n",
    "    dataset = dataset.enumerate()\n",
    "    train_dataset = dataset.filter(lambda f, data: f % 100 >= validation_data_percent)\n",
    "    validation_dataset = dataset.filter(lambda f, data: f % 100 < validation_data_percent)\n",
    "\n",
    "    # remove enumeration\n",
    "    train_dataset = train_dataset.map(lambda f, data: data)\n",
    "    validation_dataset = validation_dataset.map(lambda f, data: data)\n",
    "\n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "def data_prep(path):\n",
    "    dataset_raw = np.load(path, allow_pickle=True)\n",
    "    arrays = np.array(dataset_raw[()][\"data\"])\n",
    "    arrays = arrays - arrays.min()\n",
    "    arrays = arrays/arrays.max()\n",
    "    arrays -= arrays.mean()\n",
    "    arrays = arrays/arrays.std()\n",
    "    if np.isnan(arrays).any() or np.isinf(arrays).any():\n",
    "        raise \"data have imperfections\"\n",
    "    print(arrays.shape)\n",
    "    labels = dataset_raw[()][\"label\"]\n",
    "    labels = np.array([x-np.array(list(set(labels))).min() for x in labels])\n",
    "    print(labels.shape)\n",
    "    return (arrays, labels)\n",
    "\n",
    "def load_data(path):\n",
    "    data, label = data_prep(path)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "    dataset = dataset.shuffle(10000)\n",
    "    train_dataset, rest = split_dataset(dataset, 0.2)\n",
    "    test_dataset, valid_dataset = split_dataset(rest, 0.5)\n",
    "    train_data = train_dataset.shuffle(1000).batch(10)\n",
    "    valid_data = valid_dataset.batch(10)\n",
    "    test_data = test_dataset.batch(10)\n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "\n",
    "def make_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    Input((1,30,30)),\n",
    "    Conv2D(filters = 8, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"c1\", data_format=\"channels_first\"),\n",
    "    Conv2D(filters = 16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"c2\", data_format=\"channels_first\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(1,1),padding=\"same\", name=\"m1\", data_format=\"channels_first\"),\n",
    "    \n",
    "    Conv2D(filters = 16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"c3\", data_format=\"channels_first\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(2,2),padding=\"valid\", name=\"m2\",data_format=\"channels_first\"),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation=\"relu\", use_bias=False),\n",
    "    Dense(5,  use_bias=False)])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59003, 1, 30, 30)\n",
      "(59003,)\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = load_data(\"/home/fe/khodabakhshandeh/Projects/radar/radar-ml/Python/box_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "c1 (Conv2D)                  (None, 8, 30, 30)         80        \n",
      "_________________________________________________________________\n",
      "c2 (Conv2D)                  (None, 16, 30, 30)        1168      \n",
      "_________________________________________________________________\n",
      "m1 (MaxPooling2D)            (None, 16, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "c3 (Conv2D)                  (None, 16, 30, 30)        2320      \n",
      "_________________________________________________________________\n",
      "m2 (MaxPooling2D)            (None, 16, 15, 15)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1843200   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 2560      \n",
      "=================================================================\n",
      "Total params: 1,849,328\n",
      "Trainable params: 1,849,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "4720/4720 [==============================] - 31s 7ms/step - loss: 0.2159 - accuracy: 0.9114 - val_loss: 0.7623 - val_accuracy: 0.6754\n",
      "Epoch 2/5\n",
      "4720/4720 [==============================] - 26s 6ms/step - loss: 0.2050 - accuracy: 0.9169 - val_loss: 0.8862 - val_accuracy: 0.6736\n",
      "Epoch 3/5\n",
      "4720/4720 [==============================] - 26s 5ms/step - loss: 0.1940 - accuracy: 0.9218 - val_loss: 0.7400 - val_accuracy: 0.7059\n",
      "Epoch 4/5\n",
      "4720/4720 [==============================] - 25s 5ms/step - loss: 0.1808 - accuracy: 0.9287 - val_loss: 0.7258 - val_accuracy: 0.7168\n",
      "Epoch 5/5\n",
      "4720/4720 [==============================] - 26s 6ms/step - loss: 0.1720 - accuracy: 0.9330 - val_loss: 0.6469 - val_accuracy: 0.7308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8d4abfced0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = make_model()\n",
    "print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "model.fit(train_data, verbose=1, validation_data=valid_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    590/Unknown - 5s 8ms/step - loss: 0.6584 - accuracy: 0.7268"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6584232585615147, 0.72677964]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save(\"base_model\")\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"base_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_data(train_data):\n",
    "    train_data.shuffle(1000)\n",
    "    _, data = split_dataset(train_data, 0.1)\n",
    "    return data\n",
    "\n",
    "def UCB1(mu, n, t):\n",
    "    P = np.sqrt(2*np.log10(t)/n)\n",
    "    P = P/P.max()\n",
    "    print(\"p:\", P)\n",
    "    index = np.argmax(np.add(mu, P))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6292 - accuracy: 0.7402/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6579 - accuracy: 0.7231/n\n",
      "reward: 0.0\n",
      "n: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "##############\n",
      "index: 1\n",
      "    480/Unknown - 4s 7ms/step - loss: 0.6740 - accuracy: 0.7210/n\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6620 - accuracy: 0.7227/n\n",
      "reward: 0.16951242117599236\n",
      "n: [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 2\n",
      "    480/Unknown - 5s 10ms/step - loss: 0.6590 - accuracy: 0.7281/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6631 - accuracy: 0.7158/n\n",
      "reward: 0.008626087987795251\n",
      "n: [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 3\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6486 - accuracy: 0.7219/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6346 - accuracy: 0.7348/n\n",
      "reward: 0.18943305732876387\n",
      "n: [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 4\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6520 - accuracy: 0.7300/n\n",
      "    480/Unknown - 5s 10ms/step - loss: 0.6525 - accuracy: 0.7302/n\n",
      "reward: 0.04415965561638586\n",
      "n: [1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 5\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6475 - accuracy: 0.7312/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6685 - accuracy: 0.7200/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 6\n",
      "    480/Unknown - 5s 10ms/step - loss: 0.6723 - accuracy: 0.7252/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6219 - accuracy: 0.7433- 3s 8m/n\n",
      "reward: 0.5543842326946712\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 7\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6896 - accuracy: 0.7221/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6348 - accuracy: 0.7354/n\n",
      "reward: 0.597854657648713\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 8\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6441 - accuracy: 0.7260/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6467 - accuracy: 0.7321/n\n",
      "reward: 0.023958411540176926\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 9\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6604 - accuracy: 0.7215/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6548 - accuracy: 0.7281/n\n",
      "reward: 0.10579338370201526\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 10\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6650 - accuracy: 0.7254- 3s 8/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6378 - accuracy: 0.7367/n\n",
      "reward: 0.32176543457426254\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 11\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6821 - accuracy: 0.7173/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6443 - accuracy: 0.7281- 4s 9m/n\n",
      "reward: 0.4282243822109498\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 12\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6620 - accuracy: 0.7248/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6590 - accuracy: 0.7333/n\n",
      "reward: 0.08015761577019771\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 13\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6434 - accuracy: 0.7306/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6457 - accuracy: 0.7312/n\n",
      "reward: 0.027625214174622447\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.02762521 0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 14\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6788 - accuracy: 0.7265/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6418 - accuracy: 0.7285/n\n",
      "reward: 0.4202986090550741\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.02762521 0.42029861 0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 15\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6564 - accuracy: 0.7258/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6664 - accuracy: 0.7144/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.02762521 0.42029861 0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 16\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6585 - accuracy: 0.7271/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6657 - accuracy: 0.7215/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.02762521 0.42029861 0.         0.         0.\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 17\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6580 - accuracy: 0.7244/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6383 - accuracy: 0.7296/n\n",
      "reward: 0.2461099739952865\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.02762521 0.42029861 0.         0.         0.24610997\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 18\n",
      "    480/Unknown - 3s 6ms/step - loss: 0.6446 - accuracy: 0.7258/n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    480/Unknown - 4s 8ms/step - loss: 0.6564 - accuracy: 0.7271/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.02762521 0.42029861 0.         0.         0.24610997\n",
      " 0.         0.        ]\n",
      "##############\n",
      "index: 19\n",
      "    480/Unknown - 4s 7ms/step - loss: 0.6435 - accuracy: 0.7294/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6376 - accuracy: 0.7348/n\n",
      "reward: 0.10889001267981642\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.59785466 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.02762521 0.42029861 0.         0.         0.24610997\n",
      " 0.         0.10889001]\n",
      "##############\n",
      "p: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "RL\n",
      "index: 7\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6636 - accuracy: 0.7277/n\n",
      "    480/Unknown - 3s 6ms/step - loss: 0.6741 - accuracy: 0.7219/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.55438423 0.29892733 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.02762521 0.42029861 0.         0.         0.24610997\n",
      " 0.         0.10889001]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 1.         0.70710678 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 6\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6590 - accuracy: 0.7273- 3s 8ms/step - loss: 0.7273 -  - 3s/n\n",
      "    480/Unknown - 5s 10ms/step - loss: 0.6659 - accuracy: 0.7319/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.10579338 0.32176543 0.42822438\n",
      " 0.08015762 0.02762521 0.42029861 0.         0.         0.24610997\n",
      " 0.         0.10889001]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.70710678 0.70710678 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 11\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6469 - accuracy: 0.7296/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6355 - accuracy: 0.7312/n\n",
      "reward: 0.1644271162678101\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.10579338 0.32176543 0.29632575\n",
      " 0.08015762 0.02762521 0.42029861 0.         0.         0.24610997\n",
      " 0.         0.10889001]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.70710678 0.70710678 1.         1.         1.         0.70710678\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 14\n",
      "    480/Unknown - 5s 10ms/step - loss: 0.6349 - accuracy: 0.7329/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6392 - accuracy: 0.7348/n\n",
      "reward: 0.00702635075334297\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 2. 1. 1. 1. 2. 1. 1. 2. 1. 1. 1. 1. 1.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.10579338 0.32176543 0.29632575\n",
      " 0.08015762 0.02762521 0.21366248 0.         0.         0.24610997\n",
      " 0.         0.10889001]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.70710678 0.70710678 1.         1.         1.         0.70710678\n",
      " 1.         1.         0.70710678 1.         1.         1.\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 10\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6635 - accuracy: 0.7194/n\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6667 - accuracy: 0.7183/n\n",
      "reward: 0.018665824693743182\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 2. 1. 1. 2. 1. 1. 1. 1. 1.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.10579338 0.17021563 0.29632575\n",
      " 0.08015762 0.02762521 0.21366248 0.         0.         0.24610997\n",
      " 0.         0.10889001]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.70710678 0.70710678 1.         1.         0.70710678 0.70710678\n",
      " 1.         1.         0.70710678 1.         1.         1.\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 17\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6644 - accuracy: 0.7260/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6570 - accuracy: 0.7298/n\n",
      "reward: 0.12417299678005862\n",
      "n: [1. 1. 1. 1. 1. 1. 2. 2. 1. 1. 2. 2. 1. 1. 2. 1. 1. 2. 1. 1.]\n",
      "mu: [0.         0.16951242 0.00862609 0.18943306 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.10579338 0.17021563 0.29632575\n",
      " 0.08015762 0.02762521 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.10889001]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.70710678 0.70710678 1.         1.         0.70710678 0.70710678\n",
      " 1.         1.         0.70710678 1.         1.         0.70710678\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 3\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6481 - accuracy: 0.7337/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6611 - accuracy: 0.7290- 4s 9ms/step - loss: 0.6618 - accuracy: 0.72/n\n",
      "reward: 0.0\n",
      "n: [1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 2. 2. 1. 1. 2. 1. 1. 2. 1. 1.]\n",
      "mu: [0.         0.16951242 0.00862609 0.09471653 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.10579338 0.17021563 0.29632575\n",
      " 0.08015762 0.02762521 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.10889001]\n",
      "##############\n",
      "p: [1.         1.         1.         0.70710678 1.         1.\n",
      " 0.70710678 0.70710678 1.         1.         0.70710678 0.70710678\n",
      " 1.         1.         0.70710678 1.         1.         0.70710678\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 1\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6512 - accuracy: 0.7271/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6496 - accuracy: 0.7233/n\n",
      "reward: 0.06584807138715339\n",
      "n: [1. 2. 1. 2. 1. 1. 2. 2. 1. 1. 2. 2. 1. 1. 2. 1. 1. 2. 1. 1.]\n",
      "mu: [0.         0.11768025 0.00862609 0.09471653 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.10579338 0.17021563 0.29632575\n",
      " 0.08015762 0.02762521 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.10889001]\n",
      "##############\n",
      "p: [1.         0.70710678 1.         0.70710678 1.         1.\n",
      " 0.70710678 0.70710678 1.         1.         0.70710678 0.70710678\n",
      " 1.         1.         0.70710678 1.         1.         0.70710678\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 19\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6779 - accuracy: 0.7221/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6512 - accuracy: 0.7267/n\n",
      "reward: 0.3173231951290899\n",
      "n: [1. 2. 1. 2. 1. 1. 2. 2. 1. 1. 2. 2. 1. 1. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.00862609 0.09471653 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.10579338 0.17021563 0.29632575\n",
      " 0.08015762 0.02762521 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [1.         0.70710678 1.         0.70710678 1.         1.\n",
      " 0.70710678 0.70710678 1.         1.         0.70710678 0.70710678\n",
      " 1.         1.         0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 9\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6694 - accuracy: 0.7208/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6426 - accuracy: 0.7325/n\n",
      "reward: 0.31776900544306586\n",
      "n: [1. 2. 1. 2. 1. 1. 2. 2. 1. 2. 2. 2. 1. 1. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.00862609 0.09471653 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.21178119 0.17021563 0.29632575\n",
      " 0.08015762 0.02762521 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [1.         0.70710678 1.         0.70710678 1.         1.\n",
      " 0.70710678 0.70710678 1.         0.70710678 0.70710678 0.70710678\n",
      " 1.         1.         0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 12\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6380 - accuracy: 0.7350/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6730 - accuracy: 0.7233/n\n",
      "reward: 0.0\n",
      "n: [1. 2. 1. 2. 1. 1. 2. 2. 1. 2. 2. 2. 2. 1. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.00862609 0.09471653 0.04415966 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.21178119 0.17021563 0.29632575\n",
      " 0.04007881 0.02762521 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [1.         0.70710678 1.         0.70710678 1.         1.\n",
      " 0.70710678 0.70710678 1.         0.70710678 0.70710678 0.70710678\n",
      " 0.70710678 1.         0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 4\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6244 - accuracy: 0.7427/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6521 - accuracy: 0.7225/n\n",
      "reward: 0.0\n",
      "n: [1. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 1. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.00862609 0.09471653 0.02207983 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.21178119 0.17021563 0.29632575\n",
      " 0.04007881 0.02762521 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [1.         0.70710678 1.         0.70710678 0.70710678 1.\n",
      " 0.70710678 0.70710678 1.         0.70710678 0.70710678 0.70710678\n",
      " 0.70710678 1.         0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 13\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6495 - accuracy: 0.7285/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6673 - accuracy: 0.7235/n\n",
      "reward: 0.0\n",
      "n: [1. 2. 1. 2. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.00862609 0.09471653 0.02207983 0.\n",
      " 0.27719212 0.29892733 0.02395841 0.21178119 0.17021563 0.29632575\n",
      " 0.04007881 0.01381261 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [1.         0.70710678 1.         0.70710678 0.70710678 1.\n",
      " 0.70710678 0.70710678 1.         0.70710678 0.70710678 0.70710678\n",
      " 0.70710678 0.70710678 0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 8\n",
      "    480/Unknown - 3s 6ms/step - loss: 0.6204 - accuracy: 0.7402/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6617 - accuracy: 0.7265/n\n",
      "reward: 0.0\n",
      "n: [1. 2. 1. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.00862609 0.09471653 0.02207983 0.\n",
      " 0.27719212 0.29892733 0.01197921 0.21178119 0.17021563 0.29632575\n",
      " 0.04007881 0.01381261 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [1.         0.70710678 1.         0.70710678 0.70710678 1.\n",
      " 0.70710678 0.70710678 0.70710678 0.70710678 0.70710678 0.70710678\n",
      " 0.70710678 0.70710678 0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 2\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6569 - accuracy: 0.7246/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6479 - accuracy: 0.7302/n\n",
      "reward: 0.1402913558432683\n",
      "n: [1. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.\n",
      " 0.27719212 0.29892733 0.01197921 0.21178119 0.17021563 0.29632575\n",
      " 0.04007881 0.01381261 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [1.         0.70710678 0.70710678 0.70710678 0.70710678 1.\n",
      " 0.70710678 0.70710678 0.70710678 0.70710678 0.70710678 0.70710678\n",
      " 0.70710678 0.70710678 0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 7\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6393 - accuracy: 0.7346/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6567 - accuracy: 0.7308/n\n",
      "reward: 0.0\n",
      "n: [1. 2. 2. 2. 2. 1. 2. 3. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.\n",
      " 0.27719212 0.19928489 0.01197921 0.21178119 0.17021563 0.29632575\n",
      " 0.04007881 0.01381261 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [1.         0.70710678 0.70710678 0.70710678 0.70710678 1.\n",
      " 0.70710678 0.57735027 0.70710678 0.70710678 0.70710678 0.70710678\n",
      " 0.70710678 0.70710678 0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 11\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6448 - accuracy: 0.7321/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6458 - accuracy: 0.7275/n\n",
      "reward: 0.03986311014838701\n",
      "n: [1. 2. 2. 2. 2. 1. 2. 3. 2. 2. 2. 3. 2. 2. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.\n",
      " 0.27719212 0.19928489 0.01197921 0.21178119 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [1.         0.70710678 0.70710678 0.70710678 0.70710678 1.\n",
      " 0.70710678 0.57735027 0.70710678 0.70710678 0.70710678 0.57735027\n",
      " 0.70710678 0.70710678 0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 0\n",
      "    480/Unknown - 3s 5ms/step - loss: 0.6504 - accuracy: 0.7335/n\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6773 - accuracy: 0.7223/n\n",
      "reward: 0.0\n",
      "n: [2. 2. 2. 2. 2. 1. 2. 3. 2. 2. 2. 3. 2. 2. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.\n",
      " 0.27719212 0.19928489 0.01197921 0.21178119 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678 1.\n",
      " 0.70710678 0.57735027 0.70710678 0.70710678 0.70710678 0.57735027\n",
      " 0.70710678 0.70710678 0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 5\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6741 - accuracy: 0.7160/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6522 - accuracy: 0.7315/n\n",
      "reward: 0.26949016032158374\n",
      "n: [2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 3. 2. 2. 2. 1. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.27719212 0.19928489 0.01197921 0.21178119 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.21366248 0.         0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678 0.70710678\n",
      " 0.70710678 0.57735027 0.70710678 0.70710678 0.70710678 0.57735027\n",
      " 0.70710678 0.70710678 0.70710678 1.         1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 15\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6719 - accuracy: 0.7198/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6495 - accuracy: 0.7229/n\n",
      "reward: 0.27386419841980864\n",
      "n: [2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 3. 2. 2. 2. 2. 1. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.27719212 0.19928489 0.01197921 0.21178119 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.21366248 0.1369321  0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678 0.70710678\n",
      " 0.70710678 0.57735027 0.70710678 0.70710678 0.70710678 0.57735027\n",
      " 0.70710678 0.70710678 0.70710678 0.70710678 1.         0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 16\n",
      "    480/Unknown - 5s 9ms/step - loss: 0.6262 - accuracy: 0.7356/n\n",
      "    480/Unknown - 3s 6ms/step - loss: 0.6422 - accuracy: 0.7312/n\n",
      "reward: 0.0\n",
      "n: [2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 1. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.27719212 0.19928489 0.01197921 0.21178119 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.21366248 0.1369321  0.         0.18514149\n",
      " 0.         0.2131066 ]\n",
      "##############\n",
      "p: [0.70710678 0.70710678 0.70710678 0.70710678 0.70710678 0.70710678\n",
      " 0.70710678 0.57735027 0.70710678 0.70710678 0.70710678 0.57735027\n",
      " 0.70710678 0.70710678 0.70710678 0.70710678 0.70710678 0.70710678\n",
      " 1.         0.70710678]\n",
      "RL\n",
      "index: 18\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6609 - accuracy: 0.7233/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6602 - accuracy: 0.7256/n\n",
      "reward: 0.05656285580771576\n",
      "n: [2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.27719212 0.19928489 0.01197921 0.21178119 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.21366248 0.1369321  0.         0.18514149\n",
      " 0.02828143 0.2131066 ]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 1.         0.81649658 1.         1.         1.         0.81649658\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 6\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6525 - accuracy: 0.7312/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6610 - accuracy: 0.7252/n\n",
      "reward: 0.0\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.18479474 0.19928489 0.01197921 0.21178119 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.21366248 0.1369321  0.         0.18514149\n",
      " 0.02828143 0.2131066 ]\n",
      "##############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.81649658 0.81649658 1.         1.         1.         0.81649658\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 14\n",
      "    480/Unknown - 3s 5ms/step - loss: 0.6791 - accuracy: 0.7225- 2s 6ms/step - loss: 0.7096 - accurac - 3s 5ms/step - loss: 0.6/n\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6326 - accuracy: 0.7292/n\n",
      "reward: 0.5152514152112418\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 2. 2. 3. 2. 2. 3. 2. 2. 2. 2. 2.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.18479474 0.19928489 0.01197921 0.21178119 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.31419213 0.1369321  0.         0.18514149\n",
      " 0.02828143 0.2131066 ]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.81649658 0.81649658 1.         1.         1.         0.81649658\n",
      " 1.         1.         0.81649658 1.         1.         1.\n",
      " 1.         1.        ]\n",
      "RL\n",
      "index: 19\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6435 - accuracy: 0.7319/n\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6596 - accuracy: 0.7190/n\n",
      "reward: 0.0\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 2. 2. 3. 2. 2. 3. 2. 2. 2. 2. 3.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.18479474 0.19928489 0.01197921 0.21178119 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.31419213 0.1369321  0.         0.18514149\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.81649658 0.81649658 1.         1.         1.         0.81649658\n",
      " 1.         1.         0.81649658 1.         1.         1.\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 9\n",
      "    480/Unknown - 5s 9ms/step - loss: 0.6611 - accuracy: 0.7204/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6600 - accuracy: 0.7237/n\n",
      "reward: 0.061382714845240556\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 3. 2. 3. 2. 2. 3. 2. 2. 2. 2. 3.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.31419213 0.1369321  0.         0.18514149\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.81649658 0.81649658 1.         0.81649658 1.         0.81649658\n",
      " 1.         1.         0.81649658 1.         1.         1.\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 17\n",
      "    480/Unknown - 5s 10ms/step - loss: 0.6361 - accuracy: 0.7317/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6335 - accuracy: 0.7335/n\n",
      "reward: 0.07566987260797738\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 3. 2. 3. 2. 2. 3. 2. 2. 3. 2. 3.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.17021563 0.2108382\n",
      " 0.04007881 0.01381261 0.31419213 0.1369321  0.         0.14865095\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.81649658 0.81649658 1.         0.81649658 1.         0.81649658\n",
      " 1.         1.         0.81649658 1.         1.         0.81649658\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 10\n",
      "    480/Unknown - 3s 7ms/step - loss: 0.6363 - accuracy: 0.7350/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6410 - accuracy: 0.7333/n\n",
      "reward: 0.002143191832875103\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 3. 3. 3. 2. 2. 3. 2. 2. 3. 2. 3.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.11419148 0.2108382\n",
      " 0.04007881 0.01381261 0.31419213 0.1369321  0.         0.14865095\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.81649658 0.81649658 1.         0.81649658 0.81649658 0.81649658\n",
      " 1.         1.         0.81649658 1.         1.         0.81649658\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 15\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6551 - accuracy: 0.7248/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6490 - accuracy: 0.7271/n\n",
      "reward: 0.11079741390810023\n",
      "n: [2. 2. 2. 2. 2. 2. 3. 3. 2. 3. 3. 3. 2. 2. 3. 3. 2. 3. 2. 3.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.13474508\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.11419148 0.2108382\n",
      " 0.04007881 0.01381261 0.31419213 0.12822054 0.         0.14865095\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         1.\n",
      " 0.81649658 0.81649658 1.         0.81649658 0.81649658 0.81649658\n",
      " 1.         1.         0.81649658 0.81649658 1.         0.81649658\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 5\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6468 - accuracy: 0.7312/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6415 - accuracy: 0.7319/n\n",
      "reward: 0.1025093754210193\n",
      "n: [2. 2. 2. 2. 2. 3. 3. 3. 2. 3. 3. 3. 2. 2. 3. 3. 2. 3. 2. 3.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.12399985\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.11419148 0.2108382\n",
      " 0.04007881 0.01381261 0.31419213 0.12822054 0.         0.14865095\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         0.81649658\n",
      " 0.81649658 0.81649658 1.         0.81649658 0.81649658 0.81649658\n",
      " 1.         1.         0.81649658 0.81649658 1.         0.81649658\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 14\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6560 - accuracy: 0.7256/n\n",
      "    480/Unknown - 4s 7ms/step - loss: 0.6703 - accuracy: 0.7200/n\n",
      "reward: 0.0\n",
      "n: [2. 2. 2. 2. 2. 3. 3. 3. 2. 3. 3. 3. 2. 2. 4. 3. 2. 3. 2. 3.]\n",
      "mu: [0.         0.11768025 0.07445872 0.09471653 0.02207983 0.12399985\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.11419148 0.2108382\n",
      " 0.04007881 0.01381261 0.23564409 0.12822054 0.         0.14865095\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         1.         1.         1.         1.         0.81649658\n",
      " 0.81649658 0.81649658 1.         0.81649658 0.81649658 0.81649658\n",
      " 1.         1.         0.70710678 0.81649658 1.         0.81649658\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 1\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6484 - accuracy: 0.7312/n\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6468 - accuracy: 0.7321/n\n",
      "reward: 0.06585900173328492\n",
      "n: [2. 3. 2. 2. 2. 3. 3. 3. 2. 3. 3. 3. 2. 2. 4. 3. 2. 3. 2. 3.]\n",
      "mu: [0.         0.1004065  0.07445872 0.09471653 0.02207983 0.12399985\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.11419148 0.2108382\n",
      " 0.04007881 0.01381261 0.23564409 0.12822054 0.         0.14865095\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         0.81649658 1.         1.         1.         0.81649658\n",
      " 0.81649658 0.81649658 1.         0.81649658 0.81649658 0.81649658\n",
      " 1.         1.         0.70710678 0.81649658 1.         0.81649658\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 3\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6712 - accuracy: 0.7250/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6420 - accuracy: 0.7344/n\n",
      "reward: 0.342122085258597\n",
      "n: [2. 3. 2. 3. 2. 3. 3. 3. 2. 3. 3. 3. 2. 2. 4. 3. 2. 3. 2. 3.]\n",
      "mu: [0.         0.1004065  0.07445872 0.17718505 0.02207983 0.12399985\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.11419148 0.2108382\n",
      " 0.04007881 0.01381261 0.23564409 0.12822054 0.         0.14865095\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         0.81649658 1.         0.81649658 1.         0.81649658\n",
      " 0.81649658 0.81649658 1.         0.81649658 0.81649658 0.81649658\n",
      " 1.         1.         0.70710678 0.81649658 1.         0.81649658\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 2\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6374 - accuracy: 0.7302/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6553 - accuracy: 0.7310/n\n",
      "reward: 0.0\n",
      "n: [2. 3. 3. 3. 2. 3. 3. 3. 2. 3. 3. 3. 2. 2. 4. 3. 2. 3. 2. 3.]\n",
      "mu: [0.         0.1004065  0.04963915 0.17718505 0.02207983 0.12399985\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.11419148 0.2108382\n",
      " 0.04007881 0.01381261 0.23564409 0.12822054 0.         0.14865095\n",
      " 0.02828143 0.14207107]\n",
      "##############\n",
      "p: [1.         0.81649658 0.81649658 0.81649658 1.         0.81649658\n",
      " 0.81649658 0.81649658 1.         0.81649658 0.81649658 0.81649658\n",
      " 1.         1.         0.70710678 0.81649658 1.         0.81649658\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 12\n",
      "    480/Unknown - 4s 8ms/step - loss: 0.6434 - accuracy: 0.7387/n\n",
      "    480/Unknown - 4s 9ms/step - loss: 0.6378 - accuracy: 0.7354/n\n",
      "reward: 0.10540934506279794\n",
      "n: [2. 3. 3. 3. 2. 3. 3. 3. 2. 3. 3. 3. 3. 2. 4. 3. 2. 3. 2. 3.]\n",
      "mu: [0.         0.1004065  0.04963915 0.17718505 0.02207983 0.12399985\n",
      " 0.18479474 0.19928489 0.01197921 0.16164837 0.11419148 0.2108382\n",
      " 0.06185565 0.01381261 0.23564409 0.12822054 0.         0.14865095\n",
      " 0.02828143 0.14207107]\n",
      "##############\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: [1.         0.81649658 0.81649658 0.81649658 1.         0.81649658\n",
      " 0.81649658 0.81649658 1.         0.81649658 0.81649658 0.81649658\n",
      " 0.81649658 1.         0.70710678 0.81649658 1.         0.81649658\n",
      " 1.         0.81649658]\n",
      "RL\n",
      "index: 18\n",
      "    360/Unknown - 2s 6ms/step - loss: 0.8114 - accuracy: 0.6592"
     ]
    }
   ],
   "source": [
    "T = 60\n",
    "W = model.layers[-2].get_weights()[0]\n",
    "n = np.zeros(20)\n",
    "mu = np.zeros_like(n)\n",
    "threshold = 0.005\n",
    "for i in range(1, T):\n",
    "    #select random train data for comparison\n",
    "    data = select_random_data(train_data)\n",
    "    \n",
    "    #selecting index exploration/exploitation\n",
    "    if np.where(n==0)[0].size == 0:\n",
    "        index = UCB1(mu, n, i)\n",
    "        print(\"RL\")\n",
    "    else:\n",
    "        index = np.where(n==0)[0][0]\n",
    "    \n",
    "    print(\"index:\", index)\n",
    "    \n",
    "    #evaluating main model\n",
    "    loss_base = model.evaluate(data)[0]\n",
    "    print(\"/n\")\n",
    "\n",
    "    \n",
    "    #setting selected node to zero and evaluating again\n",
    "    W_ = np.copy(W)\n",
    "    W_[:, index] = 0\n",
    "    model.layers[-2].set_weights([W_])\n",
    "    loss = model.evaluate(data)[0]\n",
    "    print(\"/n\")\n",
    "    \n",
    "    #calculating delta and reward\n",
    "    delta = loss_base - loss\n",
    "    reward = max(0, threshold + delta)/0.1\n",
    "    print(\"reward:\", reward)\n",
    "    \n",
    "    #updating number of visiting the node and the average reward\n",
    "    n[index] = n[index]+1\n",
    "    print(\"n:\", n)\n",
    "    mu[index] = ((n[index]-1)/n[index])*mu[index] + (1/n[index])*reward\n",
    "    print(\"mu:\", mu)\n",
    "    print(\"##############\")\n",
    "    #initializing the layer to the original trained weights for next round\n",
    "    model.layers[-2].set_weights([W])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 4., 2., 3., 3., 3., 2., 3., 3.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08734847, 0.09009925, 0.17142199, 0.        , 0.2195965 ,\n",
       "       0.05465102, 0.15269722, 0.        , 0.16692901, 0.11539575])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.70710678 0.57735027 0.5        0.4472136  0.40824829\n",
      " 0.37796447 0.35355339 0.33333333 0.31622777 0.30151134 0.28867513\n",
      " 0.2773501  0.26726124 0.25819889 0.25       0.24253563 0.23570226\n",
      " 0.22941573 0.2236068  0.21821789 0.21320072 0.20851441 0.20412415\n",
      " 0.2        0.19611614 0.19245009 0.18898224 0.18569534 0.18257419\n",
      " 0.1796053  0.1767767  0.17407766 0.17149859 0.16903085 0.16666667\n",
      " 0.16439899 0.16222142 0.16012815 0.15811388 0.15617376 0.15430335\n",
      " 0.15249857 0.15075567 0.1490712  0.14744196 0.14586499 0.14433757\n",
      " 0.14285714 0.14142136 0.14002801 0.13867505 0.13736056 0.13608276\n",
      " 0.13483997 0.13363062 0.13245324 0.13130643 0.13018891 0.12909944\n",
      " 0.12803688 0.12700013 0.12598816 0.125      0.12403473 0.12309149\n",
      " 0.12216944 0.12126781 0.12038585 0.11952286 0.11867817 0.11785113\n",
      " 0.11704115 0.11624764 0.11547005 0.11470787 0.11396058 0.1132277\n",
      " 0.11250879 0.1118034  0.11111111 0.11043153 0.10976426 0.10910895\n",
      " 0.10846523 0.10783277 0.10721125 0.10660036 0.10599979 0.10540926\n",
      " 0.10482848 0.10425721 0.10369517 0.10314212 0.10259784 0.10206207\n",
      " 0.10153462 0.10101525 0.10050378 0.1       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8d3c61ea90>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.arange(100)+1\n",
    "t = sum(a)\n",
    "p=np.sqrt(2*np.log10(t)/a)\n",
    "pp = p/p.max()\n",
    "print(pp)\n",
    "plt.plot(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6130902 , 1.93131806, 1.65854132, 1.93131806, 1.60969079])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p+m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'argmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-1f9a7cd9affb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'argmax' is not defined"
     ]
    }
   ],
   "source": [
    "mu[argmax(mu)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,3,2,1,1,1])\n",
    "a[2] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 3, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
