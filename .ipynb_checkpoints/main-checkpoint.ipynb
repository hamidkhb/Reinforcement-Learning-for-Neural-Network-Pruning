{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import importlib\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SGECluster\n",
    "import socket\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, MaxPool2D, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.66.20.3:35240</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.66.20.3:8787/status' target='_blank'>http://10.66.20.3:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>540.49 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.66.20.3:35240' processes=4 threads=16, memory=540.49 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hostname = socket.gethostname()\n",
    "n_workers = 4\n",
    "n_cores = 4\n",
    "\n",
    "wks2 = \"wn-wks2.fe.hhi.de\"\n",
    "gpu1 = \"wn-gpu1.fe.hhi.de\"\n",
    "gpu2 = \"wn-gpu-104-01.fe.hhi.de\"\n",
    "\n",
    "if hostname == wks2:\n",
    "    path = \"/data/cluster/projects/infineon-radar/daq_x-har/3_Walking_converted/recording-2020-01-28_11-31-55\"\n",
    "    mem = \"20G\"      # Allocated memory is critical. For this example it must be at least 16GB \n",
    "    q = \"wn-37.q\"    # Check current queue status on https://hpc-management.fe.hhi.de/wn/phpqstat/\n",
    "    \n",
    "    cluster = SGECluster(n_workers=n_workers, cores=n_cores, memory=mem,\n",
    "                        resource_spec=f\"h_vmem={mem}\", host=hostname, queue=q,\n",
    "                         job_extra=[\"-v MKL_NUM_THREADS=1,NUMEXPR_NUM_THREADS=1,OMP_NUM_THREADS=1\"])\n",
    "elif hostname in (gpu1, gpu2):\n",
    "    path = os.getcwd() + \"/data\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,3\"  # Check current status with nvidia-smi and pick GPU from 0-3\n",
    "    cluster = LocalCluster(n_workers=n_workers, threads_per_worker=n_cores, host=hostname)\n",
    "else:\n",
    "    raise ValueError(f\"{hostname} is not a supported host. Please run this example on {wks}, {gpu1} or {gpu2}.\")\n",
    "    \n",
    "\n",
    "    \n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(n_workers=n_workers)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset: tf.data.Dataset, validation_data_fraction: float):\n",
    "\n",
    "    validation_data_percent = round(validation_data_fraction * 100)\n",
    "    if not (0 <= validation_data_percent <= 100):\n",
    "        raise ValueError(\"validation data fraction must be âˆˆ [0,1]\")\n",
    "\n",
    "    dataset = dataset.enumerate()\n",
    "    train_dataset = dataset.filter(lambda f, data: f % 100 >= validation_data_percent)\n",
    "    validation_dataset = dataset.filter(lambda f, data: f % 100 < validation_data_percent)\n",
    "\n",
    "    # remove enumeration\n",
    "    train_dataset = train_dataset.map(lambda f, data: data)\n",
    "    validation_dataset = validation_dataset.map(lambda f, data: data)\n",
    "\n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "def data_prep(path):\n",
    "    dataset_raw = np.load(path, allow_pickle=True)\n",
    "    arrays = np.array(dataset_raw[()][\"data\"])\n",
    "    arrays = arrays - arrays.min()\n",
    "    arrays = arrays/arrays.max()\n",
    "    arrays -= arrays.mean()\n",
    "    arrays = arrays/arrays.std()\n",
    "    if np.isnan(arrays).any() or np.isinf(arrays).any():\n",
    "        raise \"data have imperfections\"\n",
    "    print(arrays.shape)\n",
    "    labels = dataset_raw[()][\"label\"]\n",
    "    labels = np.array([x-np.array(list(set(labels))).min() for x in labels])\n",
    "    print(labels.shape)\n",
    "    return (arrays, labels)\n",
    "\n",
    "def load_data(path):\n",
    "    data, label = data_prep(path)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "    dataset = dataset.shuffle(10000)\n",
    "    train_dataset, rest = split_dataset(dataset, 0.2)\n",
    "    test_dataset, valid_dataset = split_dataset(rest, 0.5)\n",
    "    train_data = train_dataset.shuffle(1000).batch(10)\n",
    "    valid_data = valid_dataset.batch(10)\n",
    "    test_data = test_dataset.batch(10)\n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "def make_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    Input((1,30,30)),\n",
    "    Conv2D(filters = 8, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"c1\", data_format=\"channels_first\"),\n",
    "    Conv2D(filters = 16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"c2\", data_format=\"channels_first\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(1,1),padding=\"same\", name=\"m1\", data_format=\"channels_first\"),\n",
    "    \n",
    "    Conv2D(filters = 16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name=\"c3\", data_format=\"channels_first\"),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(2,2),padding=\"valid\", name=\"m2\",data_format=\"channels_first\"),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation=\"relu\", use_bias=False),\n",
    "    Dense(5,  use_bias=False)])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59003, 1, 30, 30)\n",
      "(59003,)\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = load_data(\"/home/fe/khodabakhshandeh/Projects/radar/radar-ml/Python/box_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "c1 (Conv2D)                  (None, 8, 30, 30)         80        \n",
      "_________________________________________________________________\n",
      "c2 (Conv2D)                  (None, 16, 30, 30)        1168      \n",
      "_________________________________________________________________\n",
      "m1 (MaxPooling2D)            (None, 16, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "c3 (Conv2D)                  (None, 16, 30, 30)        2320      \n",
      "_________________________________________________________________\n",
      "m2 (MaxPooling2D)            (None, 16, 15, 15)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               1843200   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 2560      \n",
      "=================================================================\n",
      "Total params: 1,849,328\n",
      "Trainable params: 1,849,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "4720/4720 [==============================] - 32s 7ms/step - loss: 0.3552 - accuracy: 0.8532 - val_loss: 1.1265 - val_accuracy: 0.5206\n",
      "Epoch 2/20\n",
      "4720/4720 [==============================] - 26s 6ms/step - loss: 0.2973 - accuracy: 0.8745 - val_loss: 0.8770 - val_accuracy: 0.5706\n",
      "Epoch 3/20\n",
      "4720/4720 [==============================] - 26s 5ms/step - loss: 0.2793 - accuracy: 0.8813 - val_loss: 0.9874 - val_accuracy: 0.5407\n",
      "Epoch 4/20\n",
      "4720/4720 [==============================] - 26s 5ms/step - loss: 0.2623 - accuracy: 0.8907 - val_loss: 1.1242 - val_accuracy: 0.5467\n",
      "Epoch 5/20\n",
      "4720/4720 [==============================] - 27s 6ms/step - loss: 0.2489 - accuracy: 0.8982 - val_loss: 1.0652 - val_accuracy: 0.6043\n",
      "Epoch 6/20\n",
      "4720/4720 [==============================] - 27s 6ms/step - loss: 0.2368 - accuracy: 0.9022 - val_loss: 1.1364 - val_accuracy: 0.6077\n",
      "Epoch 7/20\n",
      "4720/4720 [==============================] - 27s 6ms/step - loss: 0.2433 - accuracy: 0.8980 - val_loss: 0.7342 - val_accuracy: 0.6558\n",
      "Epoch 8/20\n",
      "4720/4720 [==============================] - 26s 6ms/step - loss: 0.2230 - accuracy: 0.9076 - val_loss: 0.8559 - val_accuracy: 0.6583\n",
      "Epoch 9/20\n",
      "4720/4720 [==============================] - 26s 6ms/step - loss: 0.2151 - accuracy: 0.9119 - val_loss: 0.8742 - val_accuracy: 0.6778\n",
      "Epoch 10/20\n",
      "4720/4720 [==============================] - 27s 6ms/step - loss: 0.2035 - accuracy: 0.9171 - val_loss: 0.7887 - val_accuracy: 0.6996\n",
      "Epoch 11/20\n",
      "4720/4720 [==============================] - 26s 6ms/step - loss: 0.1984 - accuracy: 0.9208 - val_loss: 0.8545 - val_accuracy: 0.6961\n",
      "Epoch 12/20\n",
      "4720/4720 [==============================] - 27s 6ms/step - loss: 0.1838 - accuracy: 0.9274 - val_loss: 0.7735 - val_accuracy: 0.6939\n",
      "Epoch 13/20\n",
      "4720/4720 [==============================] - 24s 5ms/step - loss: 0.1743 - accuracy: 0.9328 - val_loss: 0.8956 - val_accuracy: 0.7215\n",
      "Epoch 14/20\n",
      "4720/4720 [==============================] - 26s 6ms/step - loss: 0.1564 - accuracy: 0.9409 - val_loss: 0.6209 - val_accuracy: 0.7464\n",
      "Epoch 15/20\n",
      "4720/4720 [==============================] - 26s 6ms/step - loss: 0.1459 - accuracy: 0.9483 - val_loss: 0.6493 - val_accuracy: 0.7434\n",
      "Epoch 16/20\n",
      "4720/4720 [==============================] - 26s 5ms/step - loss: 0.1260 - accuracy: 0.9556 - val_loss: 0.4645 - val_accuracy: 0.8128\n",
      "Epoch 17/20\n",
      "4720/4720 [==============================] - 26s 6ms/step - loss: 0.1108 - accuracy: 0.9613 - val_loss: 0.5708 - val_accuracy: 0.7926\n",
      "Epoch 18/20\n",
      "4720/4720 [==============================] - 27s 6ms/step - loss: 0.1041 - accuracy: 0.9646 - val_loss: 0.4613 - val_accuracy: 0.8220\n",
      "Epoch 19/20\n",
      "4720/4720 [==============================] - 26s 5ms/step - loss: 0.0896 - accuracy: 0.9695 - val_loss: 0.3869 - val_accuracy: 0.8480\n",
      "Epoch 20/20\n",
      "4720/4720 [==============================] - 27s 6ms/step - loss: 0.0862 - accuracy: 0.9720 - val_loss: 0.4266 - val_accuracy: 0.8467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2887328510>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model()\n",
    "print(model.summary())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "model.fit(train_data, verbose=1, validation_data=valid_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: base_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"base_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    590/Unknown - 5s 8ms/step - loss: 0.4160 - accuracy: 0.8497"
     ]
    }
   ],
   "source": [
    "test = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = (list(model.layers))[-2]\n",
    "weights = layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    590/Unknown - 4s 7ms/step - loss: 1.6094 - accuracy: 0.1954"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6094379425048828, 0.19542372]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0][:] = 0  \n",
    "model.layers[-2].set_weights(weights)\n",
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "layer = (list(model.layers))[-2]\n",
    "weights = layer.get_weights()\n",
    "print(weights[0][:10,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
